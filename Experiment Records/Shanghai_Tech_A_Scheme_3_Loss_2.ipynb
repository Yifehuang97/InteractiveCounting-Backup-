{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Shanghai Tech A Scheme 3 Loss 2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6ef7b3ae592a46b4ab6096f56159b434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ac326194c971472dbecf71e5e29ec1b4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e5a7641fc40a4dadac1de1699cff35ff",
              "IPY_MODEL_bf9a3107a6d34461bc0b41757d9265eb",
              "IPY_MODEL_3c29c130ed8c40e797e060b0db7c8eee"
            ]
          }
        },
        "ac326194c971472dbecf71e5e29ec1b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5a7641fc40a4dadac1de1699cff35ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_48f959dc7e3a49cc805d0851f4165f33",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f74e43763f341e19f60ff2416db7dc4"
          }
        },
        "bf9a3107a6d34461bc0b41757d9265eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_eabfeac8e3b0415da70297a4b6d327a6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 574673361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 574673361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_638a693d6779449597ba985a4e05ce29"
          }
        },
        "3c29c130ed8c40e797e060b0db7c8eee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e0f22ad0ff9b4963a4ab0c5a1c5c2b37",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 548M/548M [00:03&lt;00:00, 160MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a4dfc983104047c7b3cca952fe7ab3f0"
          }
        },
        "48f959dc7e3a49cc805d0851f4165f33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f74e43763f341e19f60ff2416db7dc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eabfeac8e3b0415da70297a4b6d327a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "638a693d6779449597ba985a4e05ce29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e0f22ad0ff9b4963a4ab0c5a1c5c2b37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a4dfc983104047c7b3cca952fe7ab3f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "az4j5ANp-kAU",
        "outputId": "eda85a7f-a142-4f53-8f13-6ebb343fb918"
      },
      "source": [
        "!/opt/bin/nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Oct 28 04:43:34 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    23W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-3oWFNw_xGG",
        "outputId": "689264f0-9476-48b3-c17d-535107263b5d"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2aC2h0IAONJ"
      },
      "source": [
        "os.chdir('/content/gdrive/My Drive/Shanghai/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXfDAJQFAWVZ"
      },
      "source": [
        "import argparse\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "import datasets.crowd as crowd\n",
        "from models import vgg19"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg6r3viFBzjn",
        "outputId": "5b1056ff-d99e-4141-979b-bf811c5fd9ac"
      },
      "source": [
        "device = 0\n",
        "crop_size = 512\n",
        "model_path = './data/model_sh_A.pth'\n",
        "data_path = './data/ShanghaiTech/part_A/'\n",
        "dataset = 'shb'\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "device = torch.device('cuda')\n",
        "dataset = crowd.Crowd_sh(os.path.join(data_path, 'test_data'), crop_size, 8, method='val')\n",
        "dataloader = torch.utils.data.DataLoader(dataset, 1, shuffle=False,\n",
        "                                         num_workers=1, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of img: 182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "6ef7b3ae592a46b4ab6096f56159b434",
            "ac326194c971472dbecf71e5e29ec1b4",
            "e5a7641fc40a4dadac1de1699cff35ff",
            "bf9a3107a6d34461bc0b41757d9265eb",
            "3c29c130ed8c40e797e060b0db7c8eee",
            "48f959dc7e3a49cc805d0851f4165f33",
            "6f74e43763f341e19f60ff2416db7dc4",
            "eabfeac8e3b0415da70297a4b6d327a6",
            "638a693d6779449597ba985a4e05ce29",
            "e0f22ad0ff9b4963a4ab0c5a1c5c2b37",
            "a4dfc983104047c7b3cca952fe7ab3f0"
          ]
        },
        "id": "mH4xxiPwC3mA",
        "outputId": "d18462a2-266b-43df-f58d-d7528ed2f7ed"
      },
      "source": [
        "model = vgg19()\n",
        "model.to(device)\n",
        "model.load_state_dict(torch.load(model_path, device))\n",
        "model.eval()\n",
        "image_errs = []"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ef7b3ae592a46b4ab6096f56159b434",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/548M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThsnxvgVFeNA"
      },
      "source": [
        "def interactive_loss(density, gt_density, mask, count_limit = 4):\n",
        "    density = density * mask\n",
        "    gt_density = gt_density * mask\n",
        "    if gt_density.sum() >= count_limit:\n",
        "        loss = max(0, count_limit - density.sum())\n",
        "    else:\n",
        "        loss = max(0, gt_density.sum() - density.sum()) + max(0, density.sum() - gt_density.sum())\n",
        "    return loss\n",
        "\n",
        "def sample_pixel(label):\n",
        "  height, width = label.shape\n",
        "  y = random.randint(0, height - 1)\n",
        "  x = random.randint(0, width - 1)\n",
        "  return y,x\n",
        "\n",
        "def random_region_sample(label):\n",
        "  max_label = np.max(label) + 1\n",
        "  random_label = np.random.randint(0, int(max_label))\n",
        "  return random_label\n",
        "\n",
        "def error_region_sample(label, density, gt_density):\n",
        "  max_label = np.max(label) + 1\n",
        "  max_error = 0\n",
        "  final_sample_label = None\n",
        "  #For all region, calculate the loss\n",
        "  for sample_label in range(max_label):\n",
        "    #The Mask\n",
        "    inter_mask = np.zeros((label.shape[0], label.shape[1]), dtype=np.uint8)\n",
        "    inter_mask[label == sample_label] = 1\n",
        "    inter_mask = torch.from_numpy(inter_mask).to(device)\n",
        "    #Error\n",
        "    inter_error = interactive_loss(density, gt_density, inter_mask)\n",
        "    #Max error\n",
        "    if max_error < inter_error:\n",
        "      max_error = inter_error\n",
        "      final_sample_label = sample_label\n",
        "  return final_sample_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAN5cNYaSRjL"
      },
      "source": [
        "#Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMPNNpEBIVWm",
        "outputId": "f0bf42a7-68f2-4718-c4bb-3816350ab0e3"
      },
      "source": [
        "import copy\n",
        "import scipy.io as sio\n",
        "import torch.optim as optim\n",
        "from region_sum_less_4 import VIS\n",
        "import torch.nn.functional as F\n",
        "image_errs = []\n",
        "mat_path = './data/ShanghaiTech/part_A/test_data/ground-truth/'\n",
        "INTER_TIMES = 1\n",
        "INGS = 20\n",
        "INLR = 5e-8\n",
        "Inter_result = [[], [], [], [], []]\n",
        "def adapted_test():\n",
        "  image_errs = []\n",
        "  for inputs, count, name in dataloader:\n",
        "      inputs = inputs.to(device)\n",
        "\n",
        "      #Get GT_density(Same Size with output)\n",
        "      density_path = 'GT_' + name[0] + '.mat'\n",
        "      density_path = os.path.join(mat_path, density_path)\n",
        "      keypoints = sio.loadmat(density_path)['image_info'][0][0][0][0][0]\n",
        "      outputs, _ = model(inputs)\n",
        "      density = outputs.squeeze()\n",
        "      h, w = density.shape[0], density.shape[1]\n",
        "      GT_density = np.zeros((h, w))\n",
        "      for i in range(keypoints.shape[0]):\n",
        "        x, y = min(int(np.rint(keypoints[i][0] / 8)), w - 1), min(int(np.rint(keypoints[i][1] / 8)), h - 1)\n",
        "        GT_density[y][x] += 1\n",
        "\n",
        "      assert GT_density.sum() == count[0].item()\n",
        "      GT_density = torch.from_numpy(GT_density).to(device)    \n",
        "      adapted_model = copy.deepcopy(model)\n",
        "      adapted_model.train()\n",
        "      '''\n",
        "      Start Interaction\n",
        "      '''\n",
        "      inter_mask_list = []\n",
        "      for inter_time in range(INTER_TIMES):\n",
        "        \n",
        "        assert inputs.size(0) == 1, 'the batch size should equal to 1'\n",
        "        outputs, _ = adapted_model(inputs)\n",
        "\n",
        "        #Vis\n",
        "        density = outputs.squeeze().detach().cpu().numpy()\n",
        "        visual = VIS(density)\n",
        "        visual.solve()\n",
        "        label = visual.Llabel\n",
        "        \n",
        "        #Sample Region Randomly\n",
        "        sample_label = random_region_sample(label)\n",
        "\n",
        "        #Get Mask\n",
        "        inter_mask_list.append(sample_label)\n",
        "        optimizer_inter = optim.Adam(adapted_model.parameters(), lr=INLR)\n",
        "        for step in range(0, INGS):\n",
        "          #Inter Opti\n",
        "          optimizer_inter.zero_grad()\n",
        "          output, _ = adapted_model(inputs)\n",
        "\n",
        "          all_inter_mask = np.zeros((label.shape[0], label.shape[1]), dtype=np.uint8)\n",
        "          for sample_label in inter_mask_list:\n",
        "            all_inter_mask[label == sample_label] = 1\n",
        "          all_inter_mask = torch.from_numpy(all_inter_mask).to(device)\n",
        "          new_count_limit = 4 * len(inter_mask_list)\n",
        "          inter_loss = interactive_loss(output, GT_density, all_inter_mask, new_count_limit)\n",
        "\n",
        "\n",
        "          #inter_loss = criterion((output * inter_mask).sum(), (gt_density * inter_mask).sum())\n",
        "          if torch.is_tensor(inter_loss):\n",
        "              inter_loss.backward()\n",
        "              optimizer_inter.step()\n",
        "        \n",
        "        '''\n",
        "        Final Test it\n",
        "        '''\n",
        "        #with torch.set_grad_enabled(False):\n",
        "        outputs, _ = adapted_model(inputs)\n",
        "        img_err = count[0].item() - torch.sum(outputs).item()\n",
        "      #print(name, img_err, count[0].item(), torch.sum(outputs).item())\n",
        "      #image_errs.append(img_err)\n",
        "        Inter_result[inter_time].append(img_err)\n",
        "  for inter_time in range(INTER_TIMES):\n",
        "    image_errs = Inter_result[inter_time]\n",
        "    image_errs = np.array(image_errs)\n",
        "    mse = np.sqrt(np.mean(np.square(image_errs)))\n",
        "    mae = np.mean(np.abs(image_errs))\n",
        "    print('{}: mae {}, mse {}\\n'.format(model_path, mae, mse))\n",
        "\n",
        "INGS = 50\n",
        "INLR = 1e-8\n",
        "INTER_TIMES = 5\n",
        "#for INTER_TIMES in [0, 1, 2, 3, 4, 5]:\n",
        "#for INGS in [20, 25, 30]:\n",
        "#  for INLR in [1e-8, 5e-8, 1e-7]:\n",
        "#    print('############################################################')\n",
        "#    print('GS: ', INGS, 'LR: ', INLR)\n",
        "adapted_test()\n",
        "#59.7 95.7\n",
        "#Not that much improve since the downsampling \n",
        "#Different hyper parameters\n",
        "#Not that genalize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3825: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3613: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./data/model_sh_A.pth: mae 59.687476336301025, mse 95.95414323492261\n",
            "\n",
            "./data/model_sh_A.pth: mae 59.92419932438777, mse 96.55484860649213\n",
            "\n",
            "./data/model_sh_A.pth: mae 59.799652225368625, mse 96.39921450292078\n",
            "\n",
            "./data/model_sh_A.pth: mae 59.76578664255666, mse 96.26930332251064\n",
            "\n",
            "./data/model_sh_A.pth: mae 59.650541703779616, mse 96.12428396843934\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfqD5dSTSdnS"
      },
      "source": [
        "#Error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfA9UvQlSepr",
        "outputId": "0bc5557f-f214-4d2b-f42b-5fd7a81a123a"
      },
      "source": [
        "import copy\n",
        "import scipy.io as sio\n",
        "import torch.optim as optim\n",
        "from region_sum_less_4 import VIS\n",
        "import torch.nn.functional as F\n",
        "image_errs = []\n",
        "mat_path = './data/ShanghaiTech/part_A/test_data/ground-truth/'\n",
        "INTER_TIMES = 1\n",
        "INGS = 20\n",
        "INLR = 5e-8\n",
        "Inter_result = [[], [], [], [], []]\n",
        "def adapted_test():\n",
        "  image_errs = []\n",
        "  for inputs, count, name in dataloader:\n",
        "      inputs = inputs.to(device)\n",
        "\n",
        "      #Get GT_density(Same Size with output)\n",
        "      density_path = 'GT_' + name[0] + '.mat'\n",
        "      density_path = os.path.join(mat_path, density_path)\n",
        "      keypoints = sio.loadmat(density_path)['image_info'][0][0][0][0][0]\n",
        "      outputs, _ = model(inputs)\n",
        "      density = outputs.squeeze()\n",
        "      h, w = density.shape[0], density.shape[1]\n",
        "      GT_density = np.zeros((h, w))\n",
        "      for i in range(keypoints.shape[0]):\n",
        "        x, y = min(int(np.rint(keypoints[i][0] / 8)), w - 1), min(int(np.rint(keypoints[i][1] / 8)), h - 1)\n",
        "        GT_density[y][x] += 1\n",
        "\n",
        "      assert GT_density.sum() == count[0].item()\n",
        "      GT_density = torch.from_numpy(GT_density).to(device)    \n",
        "      adapted_model = copy.deepcopy(model)\n",
        "      adapted_model.train()\n",
        "      '''\n",
        "      Start Interaction\n",
        "      '''\n",
        "      inter_mask_list = []\n",
        "      for inter_time in range(INTER_TIMES):\n",
        "        \n",
        "        assert inputs.size(0) == 1, 'the batch size should equal to 1'\n",
        "        outputs, _ = adapted_model(inputs)\n",
        "\n",
        "        #Vis\n",
        "        density = outputs.squeeze().detach().cpu().numpy()\n",
        "        visual = VIS(density)\n",
        "        visual.solve()\n",
        "        label = visual.Llabel\n",
        "        \n",
        "        #Sample Region Randomly\n",
        "        #sample_label = random_region_sample(label)\n",
        "        sample_label = error_region_sample(label, outputs.squeeze(), GT_density)\n",
        "        #Get Mask\n",
        "        inter_mask_list.append(sample_label)\n",
        "        optimizer_inter = optim.Adam(adapted_model.parameters(), lr=INLR)\n",
        "        for step in range(0, INGS):\n",
        "          #Inter Opti\n",
        "          optimizer_inter.zero_grad()\n",
        "          output, _ = adapted_model(inputs)\n",
        "\n",
        "\n",
        "          all_inter_mask = np.zeros((label.shape[0], label.shape[1]), dtype=np.uint8)\n",
        "          for sample_label in inter_mask_list:\n",
        "            all_inter_mask[label == sample_label] = 1\n",
        "          all_inter_mask = torch.from_numpy(all_inter_mask).to(device)\n",
        "          new_count_limit = 4 * len(inter_mask_list)\n",
        "          inter_loss = interactive_loss(output, GT_density, all_inter_mask, new_count_limit)\n",
        "\n",
        "\n",
        "          if torch.is_tensor(inter_loss):\n",
        "              inter_loss.backward()\n",
        "              optimizer_inter.step()\n",
        "        \n",
        "        '''\n",
        "        Final Test it\n",
        "        '''\n",
        "        #with torch.set_grad_enabled(False):\n",
        "        outputs, _ = adapted_model(inputs)\n",
        "        img_err = count[0].item() - torch.sum(outputs).item()\n",
        "      #print(name, img_err, count[0].item(), torch.sum(outputs).item())\n",
        "      #image_errs.append(img_err)\n",
        "        Inter_result[inter_time].append(img_err)\n",
        "  for inter_time in range(INTER_TIMES):\n",
        "    image_errs = Inter_result[inter_time]\n",
        "    image_errs = np.array(image_errs)\n",
        "    mse = np.sqrt(np.mean(np.square(image_errs)))\n",
        "    mae = np.mean(np.abs(image_errs))\n",
        "    print('{}: mae {}, mse {}\\n'.format(model_path, mae, mse))\n",
        "\n",
        "INGS = 50\n",
        "INLR = 1e-8\n",
        "INTER_TIMES = 5\n",
        "#for INTER_TIMES in [0, 1, 2, 3, 4, 5]:\n",
        "#for INGS in [20, 25, 30]:\n",
        "#  for INLR in [1e-8, 5e-8, 1e-7]:\n",
        "#    print('############################################################')\n",
        "#    print('GS: ', INGS, 'LR: ', INLR)\n",
        "adapted_test()\n",
        "#59.7 95.7\n",
        "#Not that much improve since the downsampling \n",
        "#Different hyper parameters\n",
        "#Not that genalize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3825: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3613: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./data/model_sh_A.pth: mae 58.35455087515024, mse 94.68365005773661\n",
            "\n",
            "./data/model_sh_A.pth: mae 57.19354157919412, mse 93.82206289853016\n",
            "\n",
            "./data/model_sh_A.pth: mae 56.53577682998154, mse 93.6305678556657\n",
            "\n",
            "./data/model_sh_A.pth: mae 55.90305324177166, mse 93.42304577526131\n",
            "\n",
            "./data/model_sh_A.pth: mae 55.40384041084038, mse 93.23015148124824\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_1rsAemPYw6"
      },
      "source": [
        "#Scheme 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvkdYRaSPcG6",
        "outputId": "f011bdc1-1eeb-4962-a5dd-016fa386edf7"
      },
      "source": [
        "import copy\n",
        "import scipy.io as sio\n",
        "import torch.optim as optim\n",
        "from region_sum_less_4 import VIS\n",
        "import torch.nn.functional as F\n",
        "image_errs = []\n",
        "mat_path = './data/ShanghaiTech/part_A/test_data/ground-truth/'\n",
        "INTER_TIMES = 1\n",
        "INGS = 20\n",
        "INLR = 5e-8\n",
        "Inter_result = [[], [], [], [], []]\n",
        "def adapted_test():\n",
        "  image_errs = []\n",
        "  for inputs, count, name in dataloader:\n",
        "      inputs = inputs.to(device)\n",
        "\n",
        "      #Get GT_density(Same Size with output)\n",
        "      density_path = 'GT_' + name[0] + '.mat'\n",
        "      density_path = os.path.join(mat_path, density_path)\n",
        "      keypoints = sio.loadmat(density_path)['image_info'][0][0][0][0][0]\n",
        "      outputs, _ = model(inputs)\n",
        "      density = outputs.squeeze()\n",
        "      h, w = density.shape[0], density.shape[1]\n",
        "      GT_density = np.zeros((h, w))\n",
        "      for i in range(keypoints.shape[0]):\n",
        "        x, y = min(int(np.rint(keypoints[i][0] / 8)), w - 1), min(int(np.rint(keypoints[i][1] / 8)), h - 1)\n",
        "        GT_density[y][x] += 1\n",
        "\n",
        "      assert GT_density.sum() == count[0].item()\n",
        "      GT_density = torch.from_numpy(GT_density).to(device)    \n",
        "      adapted_model = copy.deepcopy(model)\n",
        "      adapted_model.train()\n",
        "      '''\n",
        "      Start Interaction\n",
        "      '''\n",
        "      inter_mask_list = []\n",
        "      for inter_time in range(INTER_TIMES):\n",
        "        \n",
        "        assert inputs.size(0) == 1, 'the batch size should equal to 1'\n",
        "        outputs, _ = adapted_model(inputs)\n",
        "\n",
        "        #Vis\n",
        "        density = outputs.squeeze().detach().cpu().numpy()\n",
        "        visual = VIS(density)\n",
        "        visual.solve()\n",
        "        label = visual.Llabel\n",
        "        \n",
        "        #Sample Region Randomly\n",
        "        #sample_label = random_region_sample(label)\n",
        "        sample_label = error_region_sample(label, outputs.squeeze(), GT_density)\n",
        "        #Get Mask\n",
        "        max_label = np.max(label) + 1\n",
        "        inter_mask_list.append(sample_label)\n",
        "        optimizer_inter = optim.Adam(adapted_model.parameters(), lr=INLR)\n",
        "        for step in range(0, INGS):\n",
        "          #Inter Opti\n",
        "          optimizer_inter.zero_grad()\n",
        "          output, _ = adapted_model(inputs)\n",
        "\n",
        "\n",
        "          all_inter_mask = np.zeros((label.shape[0], label.shape[1]), dtype=np.uint8)\n",
        "          for sample_label in range(max_label):\n",
        "            all_inter_mask[label == sample_label] = 1\n",
        "          all_inter_mask = torch.from_numpy(all_inter_mask).to(device)\n",
        "          new_count_limit = 4 * max_label\n",
        "          inter_loss = interactive_loss(output, GT_density, all_inter_mask, new_count_limit)\n",
        "\n",
        "\n",
        "          if torch.is_tensor(inter_loss):\n",
        "              inter_loss.backward()\n",
        "              optimizer_inter.step()\n",
        "        \n",
        "        '''\n",
        "        Final Test it\n",
        "        '''\n",
        "        #with torch.set_grad_enabled(False):\n",
        "        outputs, _ = adapted_model(inputs)\n",
        "        img_err = count[0].item() - torch.sum(outputs).item()\n",
        "      #print(name, img_err, count[0].item(), torch.sum(outputs).item())\n",
        "      #image_errs.append(img_err)\n",
        "        Inter_result[inter_time].append(img_err)\n",
        "  for inter_time in range(INTER_TIMES):\n",
        "    image_errs = Inter_result[inter_time]\n",
        "    image_errs = np.array(image_errs)\n",
        "    mse = np.sqrt(np.mean(np.square(image_errs)))\n",
        "    mae = np.mean(np.abs(image_errs))\n",
        "    print('{}: mae {}, mse {}\\n'.format(model_path, mae, mse))\n",
        "\n",
        "INGS = 50\n",
        "INLR = 1e-8\n",
        "INTER_TIMES = 5\n",
        "#for INTER_TIMES in [0, 1, 2, 3, 4, 5]:\n",
        "#for INGS in [20, 25, 30]:\n",
        "#  for INLR in [1e-8, 5e-8, 1e-7]:\n",
        "#    print('############################################################')\n",
        "#    print('GS: ', INGS, 'LR: ', INLR)\n",
        "adapted_test()\n",
        "#59.7 95.7\n",
        "#Not that much improve since the downsampling \n",
        "#Different hyper parameters\n",
        "#Not that genalize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3825: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3613: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./data/model_sh_A.pth: mae 59.46292254688976, mse 95.51016338797476\n",
            "\n",
            "./data/model_sh_A.pth: mae 59.3418162209647, mse 95.45176849376902\n",
            "\n",
            "./data/model_sh_A.pth: mae 59.23593330383301, mse 95.39853152147597\n",
            "\n",
            "./data/model_sh_A.pth: mae 59.14420647673555, mse 95.35018041845179\n",
            "\n",
            "./data/model_sh_A.pth: mae 59.05453279516199, mse 95.30576798387463\n",
            "\n"
          ]
        }
      ]
    }
  ]
}