{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FSC VAL Scheme 3 Loss 1",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Y4DR-1mFMm_",
        "outputId": "c5084c60-a21d-4b8c-fe25-00acadc2653a"
      },
      "source": [
        "!/opt/bin/nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct 26 19:25:03 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxLoabda8Igd",
        "outputId": "d881d992-bbe1-4b97-dcff-40900ef671a2"
      },
      "source": [
        "#For A100-SXM4-40GB\n",
        "!pip3 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.9.0+cu111 in /usr/local/lib/python3.7/dist-packages (1.9.0+cu111)\n",
            "Requirement already satisfied: torchvision==0.10.0+cu111 in /usr/local/lib/python3.7/dist-packages (0.10.0+cu111)\n",
            "Collecting torchaudio==0.9.0\n",
            "  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu111) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (1.19.5)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (7.1.2)\n",
            "Installing collected packages: torchaudio\n",
            "Successfully installed torchaudio-0.9.0\n",
            "1.9.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39R1mhhaFo_U",
        "outputId": "8818a0b2-59c1-4a70-bbf2-503d818fed1e"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rke22OIwpcOw"
      },
      "source": [
        "os.chdir('/content/gdrive/My Drive/Interactive/Code/Data')\n",
        "!unzip annotated_test_images.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWC6vH4dpedf"
      },
      "source": [
        "!unzip FSC147_384_V2.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVng2mnuIV_6"
      },
      "source": [
        "os.chdir('/content/gdrive/My Drive/Interactive Counting/')\n",
        "import os\n",
        "import cv2\n",
        "import copy\n",
        "import json\n",
        "import torch\n",
        "import random\n",
        "import datetime\n",
        "import numpy as np\n",
        "from utils import matlab_style_gauss2D\n",
        "from region_sum_less_4 import VIS\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from dataset import FscBgDataset\n",
        "from Kernel_Resdiual_Learning import resdiual_learning\n",
        "from utils import extract_features, TransformTrain, MincountLoss, PerturbationLoss\n",
        "from model import Resnet50FPN, FixedCountRegressor, AdaptedCountRegressor, CountRegressor, weights_normal_init"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12UsoDtNIYM9"
      },
      "source": [
        "Root_dir = '/content/gdrive/My Drive/Interactive/Code/Data/'\n",
        "Save_dir = '/content/gdrive/My Drive/Interactive Counting/Saves/'\n",
        "Model_dir = os.path.join(Root_dir, 'FamNet_Pretrained.pth')\n",
        "train_dataset = FscBgDataset(Root_dir, 'train', False)\n",
        "val_dataset = FscBgDataset(Root_dir, 'val', False)\n",
        "test_dataset = FscBgDataset(Root_dir, 'test', False)\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda:0\"\n",
        "else:\n",
        "    device = 'cpu'\n",
        "resnet50_conv = Resnet50FPN()\n",
        "resnet50_conv.to(device)\n",
        "regressor = CountRegressor(6, pool='mean')\n",
        "regressor.load_state_dict(torch.load(Model_dir))\n",
        "regressor.to(device)\n",
        "resnet50_conv.eval()\n",
        "regressor.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljbCO1WUIaLM"
      },
      "source": [
        "def interactive_loss(density, gt_density, mask, count_limit = 4):\n",
        "    density = density * mask\n",
        "    gt_density = gt_density * mask\n",
        "    if gt_density.sum() >= count_limit:\n",
        "        loss = max(0, count_limit - density.sum())\n",
        "    else:\n",
        "        loss = max(0, gt_density.sum() - density.sum()) + max(0, density.sum() - gt_density.sum())\n",
        "    return loss\n",
        "\n",
        "def sample_pixel(label):\n",
        "  height, width = label.shape\n",
        "  y = random.randint(0, height - 1)\n",
        "  x = random.randint(0, width - 1)\n",
        "  return y,x\n",
        "\n",
        "def random_region_sample(label):\n",
        "  max_label = np.max(label) + 1\n",
        "  random_label = np.random.randint(0, int(max_label))\n",
        "  return random_label\n",
        "\n",
        "def error_region_sample(label, density, gt_density):\n",
        "  max_label = np.max(label) + 1\n",
        "  max_error = 0\n",
        "  final_sample_label = None\n",
        "  #For all region, calculate the loss\n",
        "  for sample_label in range(max_label):\n",
        "    #The Mask\n",
        "    inter_mask = np.zeros((label.shape[0], label.shape[1]), dtype=np.uint8)\n",
        "    inter_mask[label == sample_label] = 1\n",
        "    inter_mask = torch.from_numpy(inter_mask).to(device)\n",
        "    #Error\n",
        "    inter_error = interactive_loss(density, gt_density, inter_mask)\n",
        "    #Max error\n",
        "    if max_error < inter_error:\n",
        "      max_error = inter_error\n",
        "      final_sample_label = sample_label\n",
        "  return final_sample_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aii70MoGG3G3"
      },
      "source": [
        "#Random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGck_xYzGthk"
      },
      "source": [
        "##Mean Region Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXsDy3zxHEV2",
        "outputId": "31819633-5af6-42b4-8632-8e21bf8e79e3"
      },
      "source": [
        "def adapted_test():\n",
        "    inter_result = [[], [], [], [], []]\n",
        "    show_detail = False\n",
        "    print(\"Adapted Test on FSC147 train set data\")\n",
        "    MAPS = ['map3', 'map4']\n",
        "    Scales = [0.9, 1.1]\n",
        "    idx_list = list(range(len(val_dataset)))\n",
        "    SAE = 0\n",
        "    SSE = 0\n",
        "    cnt = 0\n",
        "    starttime = datetime.datetime.now()\n",
        "    criterion = torch.nn.MSELoss().cuda()\n",
        "    \n",
        "    for idx in idx_list:\n",
        "        test_sample = val_dataset[idx]\n",
        "        im_id, image, boxes, dots, bg_mask_img, density = test_sample['im_id'], test_sample['image'], test_sample['boxes'], test_sample['dots'], test_sample['bg_mask_img'], test_sample['gt_density']\n",
        "        sample = {'image': image, 'lines_boxes': boxes, 'gt_density': density}\n",
        "        sample = TransformTrain(sample)\n",
        "        image, boxes, gt_density = sample['image'].to(device), sample['boxes'].to(device), sample['gt_density'].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            features = extract_features(resnet50_conv, image.unsqueeze(0), boxes.unsqueeze(0), MAPS, Scales)\n",
        "        adapted_regressor = copy.deepcopy(regressor)\n",
        "\n",
        "        '''\n",
        "        Do the Test-Adaptation\n",
        "        '''\n",
        "\n",
        "        if Test_Adaptation:\n",
        "          adapted_regressor.train()\n",
        "          optimizer = optim.Adam(adapted_regressor.parameters(), lr=ADLR)\n",
        "          features.required_grad = True\n",
        "          for step in range(0, GS):\n",
        "              optimizer.zero_grad()\n",
        "              output = adapted_regressor(features)\n",
        "              lCount = weight_mincount * MincountLoss(output, boxes)\n",
        "              lPerturbation = weight_perturbation * PerturbationLoss(output, boxes, sigma=8)\n",
        "              loss = lCount + lPerturbation\n",
        "              if torch.is_tensor(loss):\n",
        "                  loss.backward()\n",
        "                  optimizer.step()\n",
        "\n",
        "        '''\n",
        "        Interaction\n",
        "        '''\n",
        "        inter_mask_list = []\n",
        "        for int_time in range(Inter_time):\n",
        "            #Inference\n",
        "            features.required_grad = False\n",
        "            output = adapted_regressor(features)\n",
        "\n",
        "            #VIS\n",
        "            density = output.squeeze().detach().cpu().numpy()\n",
        "            visual = VIS(density)\n",
        "            visual.solve()\n",
        "            label = visual.Llabel\n",
        "\n",
        "            #Sample Region Randomly\n",
        "            sample_label = random_region_sample(label)\n",
        "\n",
        "            #Get Mask\n",
        "            inter_mask = np.zeros((label.shape[0], label.shape[1]), dtype=np.uint8)\n",
        "            inter_mask[label == sample_label] = 1\n",
        "            inter_mask = torch.from_numpy(inter_mask).to(device)\n",
        "            inter_mask_list.append(inter_mask)\n",
        "            #Reshape The GT\n",
        "            if int_time < 1:\n",
        "                gt_density = F.interpolate(gt_density, size=(inter_mask.shape[0], inter_mask.shape[1]),\n",
        "                                           mode='bilinear').squeeze()\n",
        "\n",
        "            #Updating with Interaction\n",
        "            optimizer_inter = optim.Adam(adapted_regressor.parameters(), lr=INLR)\n",
        "            features.required_grad = True\n",
        "            for step in range(0, INGS):\n",
        "                #Inter Opti\n",
        "                optimizer_inter.zero_grad()\n",
        "                output = adapted_regressor(features).squeeze()\n",
        "                inter_loss = 0\n",
        "                #Scheme 2\n",
        "                for inmask in inter_mask_list:\n",
        "                  inter_loss += interactive_loss(output, gt_density, inmask)\n",
        "                inter_loss /= len(inter_mask_list)\n",
        "                #inter_loss = criterion((output * inter_mask).sum(), (gt_density * inter_mask).sum())\n",
        "                if torch.is_tensor(inter_loss):\n",
        "                    inter_loss.backward()\n",
        "                    optimizer_inter.step()\n",
        "\n",
        "            '''\n",
        "            After Interaction\n",
        "            '''\n",
        "\n",
        "            features.required_grad = False\n",
        "            output = adapted_regressor(features).squeeze()\n",
        "            pred_cnt = output.sum().item()\n",
        "            gt_cnt = dots.shape[0]\n",
        "            cnt = cnt + 1\n",
        "            err = gt_cnt - pred_cnt\n",
        "            inter_result[int_time].append(err)\n",
        "        assert len(inter_mask_list) == 5\n",
        "    return inter_result\n",
        "\n",
        "###############################################Adaptation##############################################\n",
        "ADLR = 1e-7\n",
        "GS = 100\n",
        "weight_mincount = 1e-9\n",
        "weight_perturbation = 1e-4\n",
        "\n",
        "###############################################Interaction#############################################\n",
        "Inter_time = 5\n",
        "INGS = 15\n",
        "INLR = 1e-6\n",
        "Test_Adaptation = True\n",
        "show_detail = False\n",
        "\n",
        "\n",
        "\n",
        "Inter_result = adapted_test()\n",
        "for inter_time in range(Inter_time):\n",
        "    image_errs = Inter_result[inter_time]\n",
        "    image_errs = np.array(image_errs)\n",
        "    mse = np.sqrt(np.mean(np.square(image_errs)))\n",
        "    mae = np.mean(np.abs(image_errs))\n",
        "    print('mae {}, mse {}\\n'.format(mae, mse))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adapted Test on FSC147 train set data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3613: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/content/gdrive/My Drive/Interactive Counting/utils.py:297: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss += F.mse_loss(X,ones)\n",
            "/content/gdrive/My Drive/Interactive Counting/region_sum_less_4.py:64: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  REGION_BOTTOM_BOUND = min(np.rint(total / prediction) * CONUT_LIMIT, 150)\n",
            "/content/gdrive/My Drive/Interactive Counting/region_sum_less_4.py:174: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  REGION_BOTTOM_BOUND = min(np.rint(total / prediction) * 10, 150)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mae 21.384172689349246, mse 68.27971198791067\n",
            "\n",
            "mae 19.921217251945617, mse 66.54502898959485\n",
            "\n",
            "mae 18.650877430988693, mse 62.587219583874436\n",
            "\n",
            "mae 17.216490101387862, mse 58.502745165399965\n",
            "\n",
            "mae 16.10183561020306, mse 54.68286011533748\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMTODe4jG7C2"
      },
      "source": [
        "##Sum Region Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2KB8QWmG9vv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3935a4d-a0cc-4fac-f2a4-a8cf6d2521f1"
      },
      "source": [
        "def adapted_test():\n",
        "    inter_result = [[], [], [], [], []]\n",
        "    show_detail = False\n",
        "    print(\"Adapted Test on FSC147 train set data\")\n",
        "    MAPS = ['map3', 'map4']\n",
        "    Scales = [0.9, 1.1]\n",
        "    idx_list = list(range(len(val_dataset)))\n",
        "    SAE = 0\n",
        "    SSE = 0\n",
        "    cnt = 0\n",
        "    starttime = datetime.datetime.now()\n",
        "    criterion = torch.nn.MSELoss().cuda()\n",
        "    \n",
        "    for idx in idx_list:\n",
        "        test_sample = val_dataset[idx]\n",
        "        im_id, image, boxes, dots, bg_mask_img, density = test_sample['im_id'], test_sample['image'], test_sample['boxes'], test_sample['dots'], test_sample['bg_mask_img'], test_sample['gt_density']\n",
        "        sample = {'image': image, 'lines_boxes': boxes, 'gt_density': density}\n",
        "        sample = TransformTrain(sample)\n",
        "        image, boxes, gt_density = sample['image'].to(device), sample['boxes'].to(device), sample['gt_density'].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            features = extract_features(resnet50_conv, image.unsqueeze(0), boxes.unsqueeze(0), MAPS, Scales)\n",
        "        adapted_regressor = copy.deepcopy(regressor)\n",
        "\n",
        "        '''\n",
        "        Do the Test-Adaptation\n",
        "        '''\n",
        "\n",
        "        if Test_Adaptation:\n",
        "          adapted_regressor.train()\n",
        "          optimizer = optim.Adam(adapted_regressor.parameters(), lr=ADLR)\n",
        "          features.required_grad = True\n",
        "          for step in range(0, GS):\n",
        "              optimizer.zero_grad()\n",
        "              output = adapted_regressor(features)\n",
        "              lCount = weight_mincount * MincountLoss(output, boxes)\n",
        "              lPerturbation = weight_perturbation * PerturbationLoss(output, boxes, sigma=8)\n",
        "              loss = lCount + lPerturbation\n",
        "              if torch.is_tensor(loss):\n",
        "                  loss.backward()\n",
        "                  optimizer.step()\n",
        "\n",
        "        '''\n",
        "        Interaction\n",
        "        '''\n",
        "        inter_mask_list = []\n",
        "        for int_time in range(Inter_time):\n",
        "            #Inference\n",
        "            features.required_grad = False\n",
        "            output = adapted_regressor(features)\n",
        "\n",
        "            #VIS\n",
        "            density = output.squeeze().detach().cpu().numpy()\n",
        "            visual = VIS(density)\n",
        "            visual.solve()\n",
        "            label = visual.Llabel\n",
        "\n",
        "            #Sample Region Randomly\n",
        "            sample_label = random_region_sample(label)\n",
        "\n",
        "            #Get Mask\n",
        "            inter_mask = np.zeros((label.shape[0], label.shape[1]), dtype=np.uint8)\n",
        "            inter_mask[label == sample_label] = 1\n",
        "            inter_mask = torch.from_numpy(inter_mask).to(device)\n",
        "            inter_mask_list.append(inter_mask)\n",
        "            #Reshape The GT\n",
        "            if int_time < 1:\n",
        "                gt_density = F.interpolate(gt_density, size=(inter_mask.shape[0], inter_mask.shape[1]),\n",
        "                                           mode='bilinear').squeeze()\n",
        "\n",
        "            #Updating with Interaction\n",
        "            optimizer_inter = optim.Adam(adapted_regressor.parameters(), lr=INLR)\n",
        "            features.required_grad = True\n",
        "            for step in range(0, INGS):\n",
        "                #Inter Opti\n",
        "                optimizer_inter.zero_grad()\n",
        "                output = adapted_regressor(features).squeeze()\n",
        "                inter_loss = 0\n",
        "                #Scheme 2\n",
        "                for inmask in inter_mask_list:\n",
        "                  inter_loss += interactive_loss(output, gt_density, inmask)\n",
        "                #inter_loss /= len(inter_mask_list)\n",
        "                #inter_loss = criterion((output * inter_mask).sum(), (gt_density * inter_mask).sum())\n",
        "                if torch.is_tensor(inter_loss):\n",
        "                    inter_loss.backward()\n",
        "                    optimizer_inter.step()\n",
        "\n",
        "            '''\n",
        "            After Interaction\n",
        "            '''\n",
        "\n",
        "            features.required_grad = False\n",
        "            output = adapted_regressor(features).squeeze()\n",
        "            pred_cnt = output.sum().item()\n",
        "            gt_cnt = dots.shape[0]\n",
        "            cnt = cnt + 1\n",
        "            err = gt_cnt - pred_cnt\n",
        "            inter_result[int_time].append(err)\n",
        "        assert len(inter_mask_list) == 5\n",
        "    return inter_result\n",
        "\n",
        "###############################################Adaptation##############################################\n",
        "ADLR = 1e-7\n",
        "GS = 100\n",
        "weight_mincount = 1e-9\n",
        "weight_perturbation = 1e-4\n",
        "\n",
        "###############################################Interaction#############################################\n",
        "Inter_time = 5\n",
        "INGS = 15\n",
        "INLR = 1e-6\n",
        "Test_Adaptation = True\n",
        "show_detail = False\n",
        "\n",
        "\n",
        "\n",
        "Inter_result = adapted_test()\n",
        "for inter_time in range(Inter_time):\n",
        "    image_errs = Inter_result[inter_time]\n",
        "    image_errs = np.array(image_errs)\n",
        "    mse = np.sqrt(np.mean(np.square(image_errs)))\n",
        "    mae = np.mean(np.abs(image_errs))\n",
        "    print('mae {}, mse {}\\n'.format(mae, mse))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adapted Test on FSC147 train set data\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3613: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/content/gdrive/My Drive/Interactive Counting/utils.py:297: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss += F.mse_loss(X,ones)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mae 20.90862682104852, mse 64.06660029834428\n",
            "\n",
            "mae 19.094449001930734, mse 60.019889818824325\n",
            "\n",
            "mae 17.73857395089062, mse 57.828539963142774\n",
            "\n",
            "mae 16.304655427602736, mse 53.75111307306015\n",
            "\n",
            "mae 15.11031068372504, mse 50.64684623554786\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AALoIjXoHYw7"
      },
      "source": [
        "#Error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNRZS4V8HbCN"
      },
      "source": [
        "##Mean Region Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OS_iTRUKF_62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "751ae3e3-b6c8-43b9-db8d-c7c1dd7c8c39"
      },
      "source": [
        "def adapted_test():\n",
        "    inter_result = [[], [], [], [], []]\n",
        "    show_detail = False\n",
        "    print(\"Adapted Test on FSC147 train set data\")\n",
        "    MAPS = ['map3', 'map4']\n",
        "    Scales = [0.9, 1.1]\n",
        "    idx_list = list(range(len(val_dataset)))\n",
        "    SAE = 0\n",
        "    SSE = 0\n",
        "    cnt = 0\n",
        "    starttime = datetime.datetime.now()\n",
        "    criterion = torch.nn.MSELoss().cuda()\n",
        "    \n",
        "    for idx in idx_list:\n",
        "        test_sample = val_dataset[idx]\n",
        "        im_id, image, boxes, dots, bg_mask_img, density = test_sample['im_id'], test_sample['image'], test_sample['boxes'], test_sample['dots'], test_sample['bg_mask_img'], test_sample['gt_density']\n",
        "        sample = {'image': image, 'lines_boxes': boxes, 'gt_density': density}\n",
        "        sample = TransformTrain(sample)\n",
        "        image, boxes, gt_density = sample['image'].to(device), sample['boxes'].to(device), sample['gt_density'].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            features = extract_features(resnet50_conv, image.unsqueeze(0), boxes.unsqueeze(0), MAPS, Scales)\n",
        "        adapted_regressor = copy.deepcopy(regressor)\n",
        "\n",
        "        '''\n",
        "        Do the Test-Adaptation\n",
        "        '''\n",
        "\n",
        "        if Test_Adaptation:\n",
        "          adapted_regressor.train()\n",
        "          optimizer = optim.Adam(adapted_regressor.parameters(), lr=ADLR)\n",
        "          features.required_grad = True\n",
        "          for step in range(0, GS):\n",
        "              optimizer.zero_grad()\n",
        "              output = adapted_regressor(features)\n",
        "              lCount = weight_mincount * MincountLoss(output, boxes)\n",
        "              lPerturbation = weight_perturbation * PerturbationLoss(output, boxes, sigma=8)\n",
        "              loss = lCount + lPerturbation\n",
        "              if torch.is_tensor(loss):\n",
        "                  loss.backward()\n",
        "                  optimizer.step()\n",
        "\n",
        "        '''\n",
        "        Interaction\n",
        "        '''\n",
        "        inter_mask_list = []\n",
        "        for int_time in range(Inter_time):\n",
        "            #Inference\n",
        "            features.required_grad = False\n",
        "            output = adapted_regressor(features)\n",
        "\n",
        "            #VIS\n",
        "            density = output.squeeze().detach().cpu().numpy()\n",
        "            visual = VIS(density)\n",
        "            visual.solve()\n",
        "            label = visual.Llabel\n",
        "            \n",
        "            #Reshape The GT\n",
        "            if int_time < 1:\n",
        "                gt_density = F.interpolate(gt_density, size=(label.shape[0], label.shape[1]),\n",
        "                                           mode='bilinear').squeeze()\n",
        "\n",
        "            #Sample Region Randomly\n",
        "            #sample_label = random_region_sample(label)\n",
        "            sample_label = error_region_sample(label, output.squeeze(), gt_density)\n",
        "\n",
        "            #Get Mask\n",
        "            inter_mask = np.zeros((label.shape[0], label.shape[1]), dtype=np.uint8)\n",
        "            inter_mask[label == sample_label] = 1\n",
        "            inter_mask = torch.from_numpy(inter_mask).to(device)\n",
        "            inter_mask_list.append(inter_mask)\n",
        "            \n",
        "\n",
        "            #Updating with Interaction\n",
        "            optimizer_inter = optim.Adam(adapted_regressor.parameters(), lr=INLR)\n",
        "            features.required_grad = True\n",
        "            for step in range(0, INGS):\n",
        "                #Inter Opti\n",
        "                optimizer_inter.zero_grad()\n",
        "                output = adapted_regressor(features).squeeze()\n",
        "                inter_loss = 0\n",
        "                #Scheme 2\n",
        "                for inmask in inter_mask_list:\n",
        "                  inter_loss += interactive_loss(output, gt_density, inmask)\n",
        "                inter_loss /= len(inter_mask_list)\n",
        "                #inter_loss = criterion((output * inter_mask).sum(), (gt_density * inter_mask).sum())\n",
        "                if torch.is_tensor(inter_loss):\n",
        "                    inter_loss.backward()\n",
        "                    optimizer_inter.step()\n",
        "\n",
        "            '''\n",
        "            After Interaction\n",
        "            '''\n",
        "\n",
        "            features.required_grad = False\n",
        "            output = adapted_regressor(features).squeeze()\n",
        "            pred_cnt = output.sum().item()\n",
        "            gt_cnt = dots.shape[0]\n",
        "            cnt = cnt + 1\n",
        "            err = gt_cnt - pred_cnt\n",
        "            inter_result[int_time].append(err)\n",
        "        assert len(inter_mask_list) == 5\n",
        "    return inter_result\n",
        "\n",
        "###############################################Adaptation##############################################\n",
        "ADLR = 1e-7\n",
        "GS = 100\n",
        "weight_mincount = 1e-9\n",
        "weight_perturbation = 1e-4\n",
        "\n",
        "###############################################Interaction#############################################\n",
        "Inter_time = 5\n",
        "INGS = 15\n",
        "INLR = 1e-6\n",
        "Test_Adaptation = True\n",
        "show_detail = False\n",
        "\n",
        "\n",
        "\n",
        "Inter_result = adapted_test()\n",
        "for inter_time in range(Inter_time):\n",
        "    image_errs = Inter_result[inter_time]\n",
        "    image_errs = np.array(image_errs)\n",
        "    mse = np.sqrt(np.mean(np.square(image_errs)))\n",
        "    mae = np.mean(np.abs(image_errs))\n",
        "    print('mae {}, mse {}\\n'.format(mae, mse))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adapted Test on FSC147 train set data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3613: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/content/gdrive/My Drive/Interactive Counting/utils.py:297: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss += F.mse_loss(X,ones)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mae 19.330815679177896, mse 64.40942649618083\n",
            "\n",
            "mae 18.146875995128745, mse 62.48263535668162\n",
            "\n",
            "mae 17.732710499044153, mse 61.76630595642545\n",
            "\n",
            "mae 16.968705448355312, mse 59.770501976607854\n",
            "\n",
            "mae 15.716270486822767, mse 57.74439777875017\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4lzBS-cHtQH"
      },
      "source": [
        "##Sum Region Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jM3RnM7GHwYi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03abf4c4-d5e0-43f7-bf2c-8f1db588ca0d"
      },
      "source": [
        "def adapted_test():\n",
        "    inter_result = [[], [], [], [], []]\n",
        "    show_detail = False\n",
        "    print(\"Adapted Test on FSC147 train set data\")\n",
        "    MAPS = ['map3', 'map4']\n",
        "    Scales = [0.9, 1.1]\n",
        "    idx_list = list(range(len(val_dataset)))\n",
        "    SAE = 0\n",
        "    SSE = 0\n",
        "    cnt = 0\n",
        "    starttime = datetime.datetime.now()\n",
        "    criterion = torch.nn.MSELoss().cuda()\n",
        "    \n",
        "    for idx in idx_list:\n",
        "        test_sample = val_dataset[idx]\n",
        "        im_id, image, boxes, dots, bg_mask_img, density = test_sample['im_id'], test_sample['image'], test_sample['boxes'], test_sample['dots'], test_sample['bg_mask_img'], test_sample['gt_density']\n",
        "        sample = {'image': image, 'lines_boxes': boxes, 'gt_density': density}\n",
        "        sample = TransformTrain(sample)\n",
        "        image, boxes, gt_density = sample['image'].to(device), sample['boxes'].to(device), sample['gt_density'].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            features = extract_features(resnet50_conv, image.unsqueeze(0), boxes.unsqueeze(0), MAPS, Scales)\n",
        "        adapted_regressor = copy.deepcopy(regressor)\n",
        "\n",
        "        '''\n",
        "        Do the Test-Adaptation\n",
        "        '''\n",
        "\n",
        "        if Test_Adaptation:\n",
        "          adapted_regressor.train()\n",
        "          optimizer = optim.Adam(adapted_regressor.parameters(), lr=ADLR)\n",
        "          features.required_grad = True\n",
        "          for step in range(0, GS):\n",
        "              optimizer.zero_grad()\n",
        "              output = adapted_regressor(features)\n",
        "              lCount = weight_mincount * MincountLoss(output, boxes)\n",
        "              lPerturbation = weight_perturbation * PerturbationLoss(output, boxes, sigma=8)\n",
        "              loss = lCount + lPerturbation\n",
        "              if torch.is_tensor(loss):\n",
        "                  loss.backward()\n",
        "                  optimizer.step()\n",
        "\n",
        "        '''\n",
        "        Interaction\n",
        "        '''\n",
        "        inter_mask_list = []\n",
        "        for int_time in range(Inter_time):\n",
        "            #Inference\n",
        "            features.required_grad = False\n",
        "            output = adapted_regressor(features)\n",
        "\n",
        "            #VIS\n",
        "            density = output.squeeze().detach().cpu().numpy()\n",
        "            visual = VIS(density)\n",
        "            visual.solve()\n",
        "            label = visual.Llabel\n",
        "            \n",
        "            #Reshape The GT\n",
        "            if int_time < 1:\n",
        "                gt_density = F.interpolate(gt_density, size=(label.shape[0], label.shape[1]),\n",
        "                                           mode='bilinear').squeeze()\n",
        "\n",
        "            #Sample Region Randomly\n",
        "            #sample_label = random_region_sample(label)\n",
        "            sample_label = error_region_sample(label, output.squeeze(), gt_density)\n",
        "\n",
        "            #Get Mask\n",
        "            inter_mask = np.zeros((label.shape[0], label.shape[1]), dtype=np.uint8)\n",
        "            inter_mask[label == sample_label] = 1\n",
        "            inter_mask = torch.from_numpy(inter_mask).to(device)\n",
        "            inter_mask_list.append(inter_mask)\n",
        "            \n",
        "\n",
        "            #Updating with Interaction\n",
        "            optimizer_inter = optim.Adam(adapted_regressor.parameters(), lr=INLR)\n",
        "            features.required_grad = True\n",
        "            for step in range(0, INGS):\n",
        "                #Inter Opti\n",
        "                optimizer_inter.zero_grad()\n",
        "                output = adapted_regressor(features).squeeze()\n",
        "                inter_loss = 0\n",
        "                #Scheme 2\n",
        "                for inmask in inter_mask_list:\n",
        "                  inter_loss += interactive_loss(output, gt_density, inmask)\n",
        "                #inter_loss /= len(inter_mask_list)\n",
        "                #inter_loss = criterion((output * inter_mask).sum(), (gt_density * inter_mask).sum())\n",
        "                if torch.is_tensor(inter_loss):\n",
        "                    inter_loss.backward()\n",
        "                    optimizer_inter.step()\n",
        "\n",
        "            '''\n",
        "            After Interaction\n",
        "            '''\n",
        "\n",
        "            features.required_grad = False\n",
        "            output = adapted_regressor(features).squeeze()\n",
        "            pred_cnt = output.sum().item()\n",
        "            gt_cnt = dots.shape[0]\n",
        "            cnt = cnt + 1\n",
        "            err = gt_cnt - pred_cnt\n",
        "            inter_result[int_time].append(err)\n",
        "        assert len(inter_mask_list) == 5\n",
        "    return inter_result\n",
        "\n",
        "###############################################Adaptation##############################################\n",
        "ADLR = 1e-7\n",
        "GS = 100\n",
        "weight_mincount = 1e-9\n",
        "weight_perturbation = 1e-4\n",
        "\n",
        "###############################################Interaction#############################################\n",
        "Inter_time = 5\n",
        "INGS = 15\n",
        "INLR = 1e-6\n",
        "Test_Adaptation = True\n",
        "show_detail = False\n",
        "\n",
        "\n",
        "\n",
        "Inter_result = adapted_test()\n",
        "for inter_time in range(Inter_time):\n",
        "    image_errs = Inter_result[inter_time]\n",
        "    image_errs = np.array(image_errs)\n",
        "    mse = np.sqrt(np.mean(np.square(image_errs)))\n",
        "    mae = np.mean(np.abs(image_errs))\n",
        "    print('mae {}, mse {}\\n'.format(mae, mse))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adapted Test on FSC147 train set data\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3613: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/content/gdrive/My Drive/Interactive Counting/utils.py:297: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss += F.mse_loss(X,ones)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mae 19.332254029358527, mse 64.4107746731638\n",
            "\n",
            "mae 18.181138529377073, mse 62.49230400336523\n",
            "\n",
            "mae 17.787760778682227, mse 61.69554592149427\n",
            "\n",
            "mae 16.988821186136867, mse 60.775610926673714\n",
            "\n",
            "mae 15.623520178149684, mse 58.89698216027053\n",
            "\n"
          ]
        }
      ]
    }
  ]
}