{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Shanghai Tech B Scheme 3 Loss 1",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "82c25bf16da84b0784c29cacfd9b5085": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_169235c41c434c3c8e14b3f004a288b8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3f17d9081a134435b9956b4c1da8465a",
              "IPY_MODEL_912dac1260d949fc87f29879fad77e9d",
              "IPY_MODEL_007e340b5fec4a048b1bffc8204b1de2"
            ]
          }
        },
        "169235c41c434c3c8e14b3f004a288b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f17d9081a134435b9956b4c1da8465a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_27b5c9f9f5364e119c59b3f3689e9326",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d2cde9c267f4f05bd3978457a59ea97"
          }
        },
        "912dac1260d949fc87f29879fad77e9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_446e62a5b99c4b95990a94170295eaed",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 574673361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 574673361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c26080f44a24bc2a731eb3d8cd0062a"
          }
        },
        "007e340b5fec4a048b1bffc8204b1de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4aa2af1aff1d46bd9bbcba8cd27d6449",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 548M/548M [00:16&lt;00:00, 34.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_76ab36203b9240f085d11acde9eeef35"
          }
        },
        "27b5c9f9f5364e119c59b3f3689e9326": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d2cde9c267f4f05bd3978457a59ea97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "446e62a5b99c4b95990a94170295eaed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c26080f44a24bc2a731eb3d8cd0062a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4aa2af1aff1d46bd9bbcba8cd27d6449": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "76ab36203b9240f085d11acde9eeef35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "az4j5ANp-kAU",
        "outputId": "5cc62a37-4124-49f7-e990-331b860321c3"
      },
      "source": [
        "!/opt/bin/nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Oct 27 17:18:49 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    23W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-3oWFNw_xGG"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2aC2h0IAONJ"
      },
      "source": [
        "os.chdir('/content/gdrive/My Drive/Shanghai/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXfDAJQFAWVZ"
      },
      "source": [
        "import argparse\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "import datasets.crowd as crowd\n",
        "from models import vgg19"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg6r3viFBzjn",
        "outputId": "33adb187-02b5-4e57-a6e6-50e82bb0745c"
      },
      "source": [
        "device = 0\n",
        "crop_size = 512\n",
        "model_path = './data/model_sh_B.pth'\n",
        "data_path = './data/ShanghaiTech/part_B/'\n",
        "dataset = 'shb'\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "device = torch.device('cuda')\n",
        "dataset = crowd.Crowd_sh(os.path.join(data_path, 'test_data'), crop_size, 8, method='val')\n",
        "dataloader = torch.utils.data.DataLoader(dataset, 1, shuffle=False,\n",
        "                                         num_workers=1, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of img: 316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "82c25bf16da84b0784c29cacfd9b5085",
            "169235c41c434c3c8e14b3f004a288b8",
            "3f17d9081a134435b9956b4c1da8465a",
            "912dac1260d949fc87f29879fad77e9d",
            "007e340b5fec4a048b1bffc8204b1de2",
            "27b5c9f9f5364e119c59b3f3689e9326",
            "5d2cde9c267f4f05bd3978457a59ea97",
            "446e62a5b99c4b95990a94170295eaed",
            "4c26080f44a24bc2a731eb3d8cd0062a",
            "4aa2af1aff1d46bd9bbcba8cd27d6449",
            "76ab36203b9240f085d11acde9eeef35"
          ]
        },
        "id": "mH4xxiPwC3mA",
        "outputId": "2385cf2a-3106-4404-9ebe-1cc886594b1d"
      },
      "source": [
        "model = vgg19()\n",
        "model.to(device)\n",
        "model.load_state_dict(torch.load(model_path, device))\n",
        "model.eval()\n",
        "image_errs = []"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82c25bf16da84b0784c29cacfd9b5085",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/548M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThsnxvgVFeNA"
      },
      "source": [
        "def interactive_loss(density, gt_density, mask, count_limit = 4):\n",
        "    density = density * mask\n",
        "    gt_density = gt_density * mask\n",
        "    if gt_density.sum() >= count_limit:\n",
        "        loss = max(0, count_limit - density.sum())\n",
        "    else:\n",
        "        loss = max(0, gt_density.sum() - density.sum()) + max(0, density.sum() - gt_density.sum())\n",
        "    return loss\n",
        "\n",
        "def sample_pixel(label):\n",
        "  height, width = label.shape\n",
        "  y = random.randint(0, height - 1)\n",
        "  x = random.randint(0, width - 1)\n",
        "  return y,x\n",
        "\n",
        "def random_region_sample(label):\n",
        "  max_label = np.max(label) + 1\n",
        "  random_label = np.random.randint(0, int(max_label))\n",
        "  return random_label\n",
        "\n",
        "def error_region_sample(label, density, gt_density):\n",
        "  max_label = np.max(label) + 1\n",
        "  max_error = 0\n",
        "  final_sample_label = None\n",
        "  #For all region, calculate the loss\n",
        "  for sample_label in range(max_label):\n",
        "    #The Mask\n",
        "    inter_mask = np.zeros((label.shape[0], label.shape[1]), dtype=np.uint8)\n",
        "    inter_mask[label == sample_label] = 1\n",
        "    inter_mask = torch.from_numpy(inter_mask).to(device)\n",
        "    #Error\n",
        "    inter_error = interactive_loss(density, gt_density, inter_mask)\n",
        "    #Max error\n",
        "    if max_error < inter_error:\n",
        "      max_error = inter_error\n",
        "      final_sample_label = sample_label\n",
        "  return final_sample_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAN5cNYaSRjL"
      },
      "source": [
        "#Random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qq0vC5vMSVTg"
      },
      "source": [
        "##Mean Region Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMPNNpEBIVWm",
        "outputId": "2da9535a-e455-48f5-8958-2cec04238fc2"
      },
      "source": [
        "import copy\n",
        "import scipy.io as sio\n",
        "import torch.optim as optim\n",
        "from region_sum_less_4 import VIS\n",
        "import torch.nn.functional as F\n",
        "image_errs = []\n",
        "mat_path = './data/ShanghaiTech/part_B/test_data/ground-truth/'\n",
        "INTER_TIMES = 1\n",
        "INGS = 20\n",
        "INLR = 5e-8\n",
        "Inter_result = [[], [], [], [], []]\n",
        "def adapted_test():\n",
        "  image_errs = []\n",
        "  for inputs, count, name in dataloader:\n",
        "      inputs = inputs.to(device)\n",
        "\n",
        "      #Get GT_density(Same Size with output)\n",
        "      density_path = 'GT_' + name[0] + '.mat'\n",
        "      density_path = os.path.join(mat_path, density_path)\n",
        "      keypoints = sio.loadmat(density_path)['image_info'][0][0][0][0][0]\n",
        "      outputs, _ = model(inputs)\n",
        "      density = outputs.squeeze()\n",
        "      h, w = density.shape[0], density.shape[1]\n",
        "      GT_density = np.zeros((h, w))\n",
        "      for i in range(keypoints.shape[0]):\n",
        "        x, y = min(int(np.rint(keypoints[i][0] / 8)), w - 1), min(int(np.rint(keypoints[i][1] / 8)), h - 1)\n",
        "        GT_density[y][x] += 1\n",
        "\n",
        "      assert GT_density.sum() == count[0].item()\n",
        "      GT_density = torch.from_numpy(GT_density).to(device)    \n",
        "      adapted_model = copy.deepcopy(model)\n",
        "      adapted_model.train()\n",
        "      '''\n",
        "      Start Interaction\n",
        "      '''\n",
        "      inter_mask_list = []\n",
        "      for inter_time in range(INTER_TIMES):\n",
        "        \n",
        "        assert inputs.size(0) == 1, 'the batch size should equal to 1'\n",
        "        outputs, _ = adapted_model(inputs)\n",
        "\n",
        "        #Vis\n",
        "        density = outputs.squeeze().detach().cpu().numpy()\n",
        "        visual = VIS(density)\n",
        "        visual.solve()\n",
        "        label = visual.Llabel\n",
        "        \n",
        "        #Sample Region Randomly\n",
        "        sample_label = random_region_sample(label)\n",
        "\n",
        "        #Get Mask\n",
        "        inter_mask = np.zeros((label.shape[0], label.shape[1]), dtype=np.uint8)\n",
        "        inter_mask[label == sample_label] = 1\n",
        "        inter_mask = torch.from_numpy(inter_mask).to(device)\n",
        "        inter_mask_list.append(inter_mask)\n",
        "        optimizer_inter = optim.Adam(adapted_model.parameters(), lr=INLR)\n",
        "        for step in range(0, INGS):\n",
        "          #Inter Opti\n",
        "          optimizer_inter.zero_grad()\n",
        "          output, _ = adapted_model(inputs)\n",
        "          inter_loss = 0\n",
        "          #Scheme 2\n",
        "          for inmask in inter_mask_list:\n",
        "            inter_loss += interactive_loss(output, GT_density, inmask)\n",
        "          inter_loss /= len(inter_mask_list)\n",
        "          #inter_loss = criterion((output * inter_mask).sum(), (gt_density * inter_mask).sum())\n",
        "          if torch.is_tensor(inter_loss):\n",
        "              inter_loss.backward()\n",
        "              optimizer_inter.step()\n",
        "        \n",
        "        '''\n",
        "        Final Test it\n",
        "        '''\n",
        "        #with torch.set_grad_enabled(False):\n",
        "        outputs, _ = adapted_model(inputs)\n",
        "        img_err = count[0].item() - torch.sum(outputs).item()\n",
        "      #print(name, img_err, count[0].item(), torch.sum(outputs).item())\n",
        "      #image_errs.append(img_err)\n",
        "        Inter_result[inter_time].append(img_err)\n",
        "  for inter_time in range(INTER_TIMES):\n",
        "    image_errs = Inter_result[inter_time]\n",
        "    image_errs = np.array(image_errs)\n",
        "    mse = np.sqrt(np.mean(np.square(image_errs)))\n",
        "    mae = np.mean(np.abs(image_errs))\n",
        "    print('{}: mae {}, mse {}\\n'.format(model_path, mae, mse))\n",
        "\n",
        "INGS = 30\n",
        "INLR = 1e-8\n",
        "INTER_TIMES = 5\n",
        "#for INTER_TIMES in [0, 1, 2, 3, 4, 5]:\n",
        "#for INGS in [20, 25, 30]:\n",
        "#  for INLR in [1e-8, 5e-8, 1e-7]:\n",
        "#    print('############################################################')\n",
        "#    print('GS: ', INGS, 'LR: ', INLR)\n",
        "adapted_test()\n",
        "#59.7 95.7\n",
        "#Not that much improve since the downsampling \n",
        "#Different hyper parameters\n",
        "#Not that genalize\n",
        "#7.4 11.8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3825: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3613: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./data/model_sh_B.pth: mae 7.332228150548814, mse 11.828073230453812\n",
            "\n",
            "./data/model_sh_B.pth: mae 7.364444756809669, mse 11.901028011258349\n",
            "\n",
            "./data/model_sh_B.pth: mae 7.4014521912683415, mse 11.987576632026256\n",
            "\n",
            "./data/model_sh_B.pth: mae 7.456820726394653, mse 12.116225423291693\n",
            "\n",
            "./data/model_sh_B.pth: mae 7.4892718369447735, mse 12.22243840561547\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XGbAE1bTPF1"
      },
      "source": [
        "##Sum Region Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n42W9OHaTht9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50d21632-8d11-45bd-fd87-911972131e70"
      },
      "source": [
        "import copy\n",
        "import scipy.io as sio\n",
        "import torch.optim as optim\n",
        "from region_sum_less_4 import VIS\n",
        "import torch.nn.functional as F\n",
        "image_errs = []\n",
        "mat_path = './data/ShanghaiTech/part_B/test_data/ground-truth/'\n",
        "INTER_TIMES = 1\n",
        "INGS = 20\n",
        "INLR = 5e-8\n",
        "Inter_result = [[], [], [], [], []]\n",
        "def adapted_test():\n",
        "  image_errs = []\n",
        "  for inputs, count, name in dataloader:\n",
        "      inputs = inputs.to(device)\n",
        "\n",
        "      #Get GT_density(Same Size with output)\n",
        "      density_path = 'GT_' + name[0] + '.mat'\n",
        "      density_path = os.path.join(mat_path, density_path)\n",
        "      keypoints = sio.loadmat(density_path)['image_info'][0][0][0][0][0]\n",
        "      outputs, _ = model(inputs)\n",
        "      density = outputs.squeeze()\n",
        "      h, w = density.shape[0], density.shape[1]\n",
        "      GT_density = np.zeros((h, w))\n",
        "      for i in range(keypoints.shape[0]):\n",
        "        x, y = min(int(np.rint(keypoints[i][0] / 8)), w - 1), min(int(np.rint(keypoints[i][1] / 8)), h - 1)\n",
        "        GT_density[y][x] += 1\n",
        "\n",
        "      assert GT_density.sum() == count[0].item()\n",
        "      GT_density = torch.from_numpy(GT_density).to(device)    \n",
        "      adapted_model = copy.deepcopy(model)\n",
        "      adapted_model.train()\n",
        "      '''\n",
        "      Start Interaction\n",
        "      '''\n",
        "      inter_mask_list = []\n",
        "      for inter_time in range(INTER_TIMES):\n",
        "        \n",
        "        assert inputs.size(0) == 1, 'the batch size should equal to 1'\n",
        "        outputs, _ = adapted_model(inputs)\n",
        "\n",
        "        #Vis\n",
        "        density = outputs.squeeze().detach().cpu().numpy()\n",
        "        visual = VIS(density)\n",
        "        visual.solve()\n",
        "        label = visual.Llabel\n",
        "        \n",
        "        #Sample Region Randomly\n",
        "        sample_label = random_region_sample(label)\n",
        "\n",
        "        #Get Mask\n",
        "        inter_mask = np.zeros((label.shape[0], label.shape[1]), dtype=np.uint8)\n",
        "        inter_mask[label == sample_label] = 1\n",
        "        inter_mask = torch.from_numpy(inter_mask).to(device)\n",
        "        inter_mask_list.append(inter_mask)\n",
        "        optimizer_inter = optim.Adam(adapted_model.parameters(), lr=INLR)\n",
        "        for step in range(0, INGS):\n",
        "          #Inter Opti\n",
        "          optimizer_inter.zero_grad()\n",
        "          output, _ = adapted_model(inputs)\n",
        "          inter_loss = 0\n",
        "          #Scheme 2\n",
        "          for inmask in inter_mask_list:\n",
        "            inter_loss += interactive_loss(output, GT_density, inmask)\n",
        "          #inter_loss /= len(inter_mask_list)\n",
        "          #inter_loss = criterion((output * inter_mask).sum(), (gt_density * inter_mask).sum())\n",
        "          if torch.is_tensor(inter_loss):\n",
        "              inter_loss.backward()\n",
        "              optimizer_inter.step()\n",
        "        \n",
        "        '''\n",
        "        Final Test it\n",
        "        '''\n",
        "        #with torch.set_grad_enabled(False):\n",
        "        outputs, _ = adapted_model(inputs)\n",
        "        img_err = count[0].item() - torch.sum(outputs).item()\n",
        "      #print(name, img_err, count[0].item(), torch.sum(outputs).item())\n",
        "      #image_errs.append(img_err)\n",
        "        Inter_result[inter_time].append(img_err)\n",
        "  for inter_time in range(INTER_TIMES):\n",
        "    image_errs = Inter_result[inter_time]\n",
        "    image_errs = np.array(image_errs)\n",
        "    mse = np.sqrt(np.mean(np.square(image_errs)))\n",
        "    mae = np.mean(np.abs(image_errs))\n",
        "    print('{}: mae {}, mse {}\\n'.format(model_path, mae, mse))\n",
        "\n",
        "INGS = 30\n",
        "INLR = 1e-8\n",
        "INTER_TIMES = 5\n",
        "#for INTER_TIMES in [0, 1, 2, 3, 4, 5]:\n",
        "#for INGS in [20, 25, 30]:\n",
        "#  for INLR in [1e-8, 5e-8, 1e-7]:\n",
        "#    print('############################################################')\n",
        "#    print('GS: ', INGS, 'LR: ', INLR)\n",
        "adapted_test()\n",
        "#59.7 95.7\n",
        "#Not that much improve since the downsampling \n",
        "#Different hyper parameters\n",
        "#Not that genalize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3825: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3613: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./data/model_sh_B.pth: mae 7.320633459694778, mse 11.778565257057942\n",
            "\n",
            "./data/model_sh_B.pth: mae 7.328646629671507, mse 11.77471430722256\n",
            "\n",
            "./data/model_sh_B.pth: mae 7.328259733658802, mse 11.763424049483868\n",
            "\n",
            "./data/model_sh_B.pth: mae 7.326949131639698, mse 11.772856396240494\n",
            "\n",
            "./data/model_sh_B.pth: mae 7.348822367342213, mse 11.809955288914995\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfqD5dSTSdnS"
      },
      "source": [
        "#Error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxvwB6GsTQ8e"
      },
      "source": [
        "##Mean Region Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfA9UvQlSepr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62b2a486-cf96-4837-a948-f8a5c03c105b"
      },
      "source": [
        "import copy\n",
        "import scipy.io as sio\n",
        "import torch.optim as optim\n",
        "from region_sum_less_4 import VIS\n",
        "import torch.nn.functional as F\n",
        "image_errs = []\n",
        "mat_path = './data/ShanghaiTech/part_B/test_data/ground-truth/'\n",
        "INTER_TIMES = 1\n",
        "INGS = 20\n",
        "INLR = 5e-8\n",
        "Inter_result = [[], [], [], [], []]\n",
        "def adapted_test():\n",
        "  image_errs = []\n",
        "  for inputs, count, name in dataloader:\n",
        "      inputs = inputs.to(device)\n",
        "\n",
        "      #Get GT_density(Same Size with output)\n",
        "      density_path = 'GT_' + name[0] + '.mat'\n",
        "      density_path = os.path.join(mat_path, density_path)\n",
        "      keypoints = sio.loadmat(density_path)['image_info'][0][0][0][0][0]\n",
        "      outputs, _ = model(inputs)\n",
        "      density = outputs.squeeze()\n",
        "      h, w = density.shape[0], density.shape[1]\n",
        "      GT_density = np.zeros((h, w))\n",
        "      for i in range(keypoints.shape[0]):\n",
        "        x, y = min(int(np.rint(keypoints[i][0] / 8)), w - 1), min(int(np.rint(keypoints[i][1] / 8)), h - 1)\n",
        "        GT_density[y][x] += 1\n",
        "\n",
        "      assert GT_density.sum() == count[0].item()\n",
        "      GT_density = torch.from_numpy(GT_density).to(device)    \n",
        "      adapted_model = copy.deepcopy(model)\n",
        "      adapted_model.train()\n",
        "      '''\n",
        "      Start Interaction\n",
        "      '''\n",
        "      inter_mask_list = []\n",
        "      for inter_time in range(INTER_TIMES):\n",
        "        \n",
        "        assert inputs.size(0) == 1, 'the batch size should equal to 1'\n",
        "        outputs, _ = adapted_model(inputs)\n",
        "\n",
        "        #Vis\n",
        "        density = outputs.squeeze().detach().cpu().numpy()\n",
        "        visual = VIS(density)\n",
        "        visual.solve()\n",
        "        label = visual.Llabel\n",
        "        \n",
        "        #Sample Region Randomly\n",
        "        #sample_label = random_region_sample(label)\n",
        "        sample_label = error_region_sample(label, outputs.squeeze(), GT_density)\n",
        "        #Get Mask\n",
        "        inter_mask = np.zeros((label.shape[0], label.shape[1]), dtype=np.uint8)\n",
        "        inter_mask[label == sample_label] = 1\n",
        "        inter_mask = torch.from_numpy(inter_mask).to(device)\n",
        "        inter_mask_list.append(inter_mask)\n",
        "        optimizer_inter = optim.Adam(adapted_model.parameters(), lr=INLR)\n",
        "        for step in range(0, INGS):\n",
        "          #Inter Opti\n",
        "          optimizer_inter.zero_grad()\n",
        "          output, _ = adapted_model(inputs)\n",
        "          inter_loss = 0\n",
        "          #Scheme 2\n",
        "          for inmask in inter_mask_list:\n",
        "            inter_loss += interactive_loss(output, GT_density, inmask)\n",
        "          inter_loss /= len(inter_mask_list)\n",
        "          #inter_loss = criterion((output * inter_mask).sum(), (gt_density * inter_mask).sum())\n",
        "          if torch.is_tensor(inter_loss):\n",
        "              inter_loss.backward()\n",
        "              optimizer_inter.step()\n",
        "        \n",
        "        '''\n",
        "        Final Test it\n",
        "        '''\n",
        "        #with torch.set_grad_enabled(False):\n",
        "        outputs, _ = adapted_model(inputs)\n",
        "        img_err = count[0].item() - torch.sum(outputs).item()\n",
        "      #print(name, img_err, count[0].item(), torch.sum(outputs).item())\n",
        "      #image_errs.append(img_err)\n",
        "        Inter_result[inter_time].append(img_err)\n",
        "  for inter_time in range(INTER_TIMES):\n",
        "    image_errs = Inter_result[inter_time]\n",
        "    image_errs = np.array(image_errs)\n",
        "    mse = np.sqrt(np.mean(np.square(image_errs)))\n",
        "    mae = np.mean(np.abs(image_errs))\n",
        "    print('{}: mae {}, mse {}\\n'.format(model_path, mae, mse))\n",
        "\n",
        "INGS = 50\n",
        "INLR = 1e-8\n",
        "INTER_TIMES = 5\n",
        "#for INTER_TIMES in [0, 1, 2, 3, 4, 5]:\n",
        "#for INGS in [20, 25, 30]:\n",
        "#  for INLR in [1e-8, 5e-8, 1e-7]:\n",
        "#    print('############################################################')\n",
        "#    print('GS: ', INGS, 'LR: ', INLR)\n",
        "adapted_test()\n",
        "#59.7 95.7\n",
        "#Not that much improve since the downsampling \n",
        "#Different hyper parameters\n",
        "#Not that genalize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3825: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3613: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./data/model_sh_B.pth: mae 7.179282330259492, mse 11.50696717101904\n",
            "\n",
            "./data/model_sh_B.pth: mae 7.102348994605149, mse 11.40135704836044\n",
            "\n",
            "./data/model_sh_B.pth: mae 7.067782773247248, mse 11.28776276030665\n",
            "\n",
            "./data/model_sh_B.pth: mae 7.05219850962675, mse 11.243700714229947\n",
            "\n",
            "./data/model_sh_B.pth: mae 7.078190752222568, mse 11.294299804902643\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDI8xJtpTaty"
      },
      "source": [
        "##Sum Region Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYaYfbXOTesC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57c247fd-9e3f-43eb-d4a4-abdd813558c0"
      },
      "source": [
        "import copy\n",
        "import scipy.io as sio\n",
        "import torch.optim as optim\n",
        "from region_sum_less_4 import VIS\n",
        "import torch.nn.functional as F\n",
        "image_errs = []\n",
        "mat_path = './data/ShanghaiTech/part_B/test_data/ground-truth/'\n",
        "INTER_TIMES = 1\n",
        "INGS = 20\n",
        "INLR = 5e-8\n",
        "Inter_result = [[], [], [], [], []]\n",
        "def adapted_test():\n",
        "  image_errs = []\n",
        "  for inputs, count, name in dataloader:\n",
        "      inputs = inputs.to(device)\n",
        "\n",
        "      #Get GT_density(Same Size with output)\n",
        "      density_path = 'GT_' + name[0] + '.mat'\n",
        "      density_path = os.path.join(mat_path, density_path)\n",
        "      keypoints = sio.loadmat(density_path)['image_info'][0][0][0][0][0]\n",
        "      outputs, _ = model(inputs)\n",
        "      density = outputs.squeeze()\n",
        "      h, w = density.shape[0], density.shape[1]\n",
        "      GT_density = np.zeros((h, w))\n",
        "      for i in range(keypoints.shape[0]):\n",
        "        x, y = min(int(np.rint(keypoints[i][0] / 8)), w - 1), min(int(np.rint(keypoints[i][1] / 8)), h - 1)\n",
        "        GT_density[y][x] += 1\n",
        "\n",
        "      assert GT_density.sum() == count[0].item()\n",
        "      GT_density = torch.from_numpy(GT_density).to(device)    \n",
        "      adapted_model = copy.deepcopy(model)\n",
        "      adapted_model.train()\n",
        "      '''\n",
        "      Start Interaction\n",
        "      '''\n",
        "      inter_mask_list = []\n",
        "      for inter_time in range(INTER_TIMES):\n",
        "        \n",
        "        assert inputs.size(0) == 1, 'the batch size should equal to 1'\n",
        "        outputs, _ = adapted_model(inputs)\n",
        "\n",
        "        #Vis\n",
        "        density = outputs.squeeze().detach().cpu().numpy()\n",
        "        visual = VIS(density)\n",
        "        visual.solve()\n",
        "        label = visual.Llabel\n",
        "        \n",
        "        #Sample Region Randomly\n",
        "        #sample_label = random_region_sample(label)\n",
        "        sample_label = error_region_sample(label, outputs.squeeze(), GT_density)\n",
        "        #Get Mask\n",
        "        inter_mask = np.zeros((label.shape[0], label.shape[1]), dtype=np.uint8)\n",
        "        inter_mask[label == sample_label] = 1\n",
        "        inter_mask = torch.from_numpy(inter_mask).to(device)\n",
        "        inter_mask_list.append(inter_mask)\n",
        "        optimizer_inter = optim.Adam(adapted_model.parameters(), lr=INLR)\n",
        "        for step in range(0, INGS):\n",
        "          #Inter Opti\n",
        "          optimizer_inter.zero_grad()\n",
        "          output, _ = adapted_model(inputs)\n",
        "          inter_loss = 0\n",
        "          #Scheme 2\n",
        "          for inmask in inter_mask_list:\n",
        "            inter_loss += interactive_loss(output, GT_density, inmask)\n",
        "          #inter_loss /= len(inter_mask_list)\n",
        "          #inter_loss = criterion((output * inter_mask).sum(), (gt_density * inter_mask).sum())\n",
        "          if torch.is_tensor(inter_loss):\n",
        "              inter_loss.backward()\n",
        "              optimizer_inter.step()\n",
        "        \n",
        "        '''\n",
        "        Final Test it\n",
        "        '''\n",
        "        #with torch.set_grad_enabled(False):\n",
        "        outputs, _ = adapted_model(inputs)\n",
        "        img_err = count[0].item() - torch.sum(outputs).item()\n",
        "      #print(name, img_err, count[0].item(), torch.sum(outputs).item())\n",
        "      #image_errs.append(img_err)\n",
        "        Inter_result[inter_time].append(img_err)\n",
        "  for inter_time in range(INTER_TIMES):\n",
        "    image_errs = Inter_result[inter_time]\n",
        "    image_errs = np.array(image_errs)\n",
        "    mse = np.sqrt(np.mean(np.square(image_errs)))\n",
        "    mae = np.mean(np.abs(image_errs))\n",
        "    print('{}: mae {}, mse {}\\n'.format(model_path, mae, mse))\n",
        "\n",
        "INGS = 50\n",
        "INLR = 1e-8\n",
        "INTER_TIMES = 5\n",
        "#for INTER_TIMES in [0, 1, 2, 3, 4, 5]:\n",
        "#for INGS in [20, 25, 30]:\n",
        "#  for INLR in [1e-8, 5e-8, 1e-7]:\n",
        "#    print('############################################################')\n",
        "#    print('GS: ', INGS, 'LR: ', INLR)\n",
        "adapted_test()\n",
        "#59.7 95.7\n",
        "#Not that much improve since the downsampling \n",
        "#Different hyper parameters\n",
        "#Not that genalize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3825: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3613: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./data/model_sh_B.pth: mae 7.1792921899240225, mse 11.50697292621664\n",
            "\n",
            "./data/model_sh_B.pth: mae 7.102370729929285, mse 11.40137532249873\n",
            "\n",
            "./data/model_sh_B.pth: mae 7.0678221575821505, mse 11.287805949227725\n",
            "\n",
            "./data/model_sh_B.pth: mae 7.0522789019572585, mse 11.243767637490741\n",
            "\n",
            "./data/model_sh_B.pth: mae 7.078279706496227, mse 11.294367267311607\n",
            "\n"
          ]
        }
      ]
    }
  ]
}