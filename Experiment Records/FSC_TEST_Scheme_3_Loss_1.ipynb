{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FSC TEST Scheme 3 Loss 1",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Y4DR-1mFMm_",
        "outputId": "3a488eea-1c04-4f4d-edf7-72bb5be60c15"
      },
      "source": [
        "!/opt/bin/nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct 26 19:15:18 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxLoabda8Igd",
        "outputId": "d881d992-bbe1-4b97-dcff-40900ef671a2"
      },
      "source": [
        "#For A100-SXM4-40GB\n",
        "!pip3 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.9.0+cu111 in /usr/local/lib/python3.7/dist-packages (1.9.0+cu111)\n",
            "Requirement already satisfied: torchvision==0.10.0+cu111 in /usr/local/lib/python3.7/dist-packages (0.10.0+cu111)\n",
            "Collecting torchaudio==0.9.0\n",
            "  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu111) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (1.19.5)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (7.1.2)\n",
            "Installing collected packages: torchaudio\n",
            "Successfully installed torchaudio-0.9.0\n",
            "1.9.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39R1mhhaFo_U",
        "outputId": "2d004d49-9c26-4b0d-ad84-d1f63c9d5904"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rke22OIwpcOw"
      },
      "source": [
        "os.chdir('/content/gdrive/My Drive/Interactive/Code/Data')\n",
        "!unzip annotated_test_images.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWC6vH4dpedf"
      },
      "source": [
        "!unzip FSC147_384_V2.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tr7FZumgG9bq"
      },
      "source": [
        "#Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fyliP9JPbVU"
      },
      "source": [
        "os.chdir('/content/gdrive/My Drive/Interactive Counting/')\n",
        "import os\n",
        "import cv2\n",
        "import copy\n",
        "import json\n",
        "import torch\n",
        "import random\n",
        "import datetime\n",
        "import numpy as np\n",
        "from utils import matlab_style_gauss2D\n",
        "from region_sum_less_4 import VIS\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from dataset import FscBgDataset\n",
        "from Kernel_Resdiual_Learning import resdiual_learning\n",
        "from utils import extract_features, TransformTrain, MincountLoss, PerturbationLoss\n",
        "from model import Resnet50FPN, FixedCountRegressor, AdaptedCountRegressor, CountRegressor, weights_normal_init"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2RveiSFGbeN"
      },
      "source": [
        "Root_dir = '/content/gdrive/My Drive/Interactive/Code/Data/'\n",
        "Save_dir = '/content/gdrive/My Drive/Interactive Counting/Saves/'\n",
        "Model_dir = os.path.join(Root_dir, 'FamNet_Pretrained.pth')\n",
        "train_dataset = FscBgDataset(Root_dir, 'train', False)\n",
        "val_dataset = FscBgDataset(Root_dir, 'val', False)\n",
        "test_dataset = FscBgDataset(Root_dir, 'test', False)\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda:0\"\n",
        "else:\n",
        "    device = 'cpu'\n",
        "resnet50_conv = Resnet50FPN()\n",
        "resnet50_conv.to(device)\n",
        "regressor = CountRegressor(6, pool='mean')\n",
        "regressor.load_state_dict(torch.load(Model_dir))\n",
        "regressor.to(device)\n",
        "resnet50_conv.eval()\n",
        "regressor.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeNxM0bCG7P4"
      },
      "source": [
        "def interactive_loss(density, gt_density, mask, count_limit = 4):\n",
        "    density = density * mask\n",
        "    gt_density = gt_density * mask\n",
        "    if gt_density.sum() >= count_limit:\n",
        "        loss = max(0, count_limit - density.sum())\n",
        "    else:\n",
        "        loss = max(0, gt_density.sum() - density.sum()) + max(0, density.sum() - gt_density.sum())\n",
        "    return loss\n",
        "\n",
        "def sample_pixel(label):\n",
        "  height, width = label.shape\n",
        "  y = random.randint(0, height - 1)\n",
        "  x = random.randint(0, width - 1)\n",
        "  return y,x\n",
        "\n",
        "def random_region_sample(label):\n",
        "  max_label = np.max(label) + 1\n",
        "  random_label = np.random.randint(0, int(max_label))\n",
        "  return random_label\n",
        "\n",
        "def error_region_sample(label, density, gt_density):\n",
        "  max_label = np.max(label) + 1\n",
        "  max_error = 0\n",
        "  final_sample_label = None\n",
        "  #For all region, calculate the loss\n",
        "  for sample_label in range(max_label):\n",
        "    #The Mask\n",
        "    inter_mask = np.zeros((label.shape[0], label.shape[1]), dtype=np.uint8)\n",
        "    inter_mask[label == sample_label] = 1\n",
        "    inter_mask = torch.from_numpy(inter_mask).to(device)\n",
        "    #Error\n",
        "    inter_error = interactive_loss(density, gt_density, inter_mask)\n",
        "    #Max error\n",
        "    if max_error < inter_error:\n",
        "      max_error = inter_error\n",
        "      final_sample_label = sample_label\n",
        "  return final_sample_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aii70MoGG3G3"
      },
      "source": [
        "#Random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGck_xYzGthk"
      },
      "source": [
        "##Mean Region Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXsDy3zxHEV2",
        "outputId": "7eed6f91-d0b1-4e61-d3e0-cafb7f9f6a98"
      },
      "source": [
        "def adapted_test():\n",
        "    inter_result = [[], [], [], [], []]\n",
        "    show_detail = False\n",
        "    print(\"Adapted Test on FSC147 train set data\")\n",
        "    MAPS = ['map3', 'map4']\n",
        "    Scales = [0.9, 1.1]\n",
        "    idx_list = list(range(len(test_dataset)))\n",
        "    SAE = 0\n",
        "    SSE = 0\n",
        "    cnt = 0\n",
        "    starttime = datetime.datetime.now()\n",
        "    criterion = torch.nn.MSELoss().cuda()\n",
        "    \n",
        "    for idx in idx_list:\n",
        "        test_sample = test_dataset[idx]\n",
        "        im_id, image, boxes, dots, bg_mask_img, density = test_sample['im_id'], test_sample['image'], test_sample['boxes'], test_sample['dots'], test_sample['bg_mask_img'], test_sample['gt_density']\n",
        "        sample = {'image': image, 'lines_boxes': boxes, 'gt_density': density}\n",
        "        sample = TransformTrain(sample)\n",
        "        image, boxes, gt_density = sample['image'].to(device), sample['boxes'].to(device), sample['gt_density'].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            features = extract_features(resnet50_conv, image.unsqueeze(0), boxes.unsqueeze(0), MAPS, Scales)\n",
        "        adapted_regressor = copy.deepcopy(regressor)\n",
        "\n",
        "        '''\n",
        "        Do the Test-Adaptation\n",
        "        '''\n",
        "\n",
        "        if Test_Adaptation:\n",
        "          adapted_regressor.train()\n",
        "          optimizer = optim.Adam(adapted_regressor.parameters(), lr=ADLR)\n",
        "          features.required_grad = True\n",
        "          for step in range(0, GS):\n",
        "              optimizer.zero_grad()\n",
        "              output = adapted_regressor(features)\n",
        "              lCount = weight_mincount * MincountLoss(output, boxes)\n",
        "              lPerturbation = weight_perturbation * PerturbationLoss(output, boxes, sigma=8)\n",
        "              loss = lCount + lPerturbation\n",
        "              if torch.is_tensor(loss):\n",
        "                  loss.backward()\n",
        "                  optimizer.step()\n",
        "\n",
        "        '''\n",
        "        Interaction\n",
        "        '''\n",
        "        inter_mask_list = []\n",
        "        for int_time in range(Inter_time):\n",
        "            #Inference\n",
        "            features.required_grad = False\n",
        "            output = adapted_regressor(features)\n",
        "\n",
        "            #VIS\n",
        "            density = output.squeeze().detach().cpu().numpy()\n",
        "            visual = VIS(density)\n",
        "            visual.solve()\n",
        "            label = visual.Llabel\n",
        "\n",
        "            #Sample Region Randomly\n",
        "            sample_label = random_region_sample(label)\n",
        "\n",
        "            #Get Mask\n",
        "            inter_mask = np.zeros((label.shape[0], label.shape[1]), dtype=np.uint8)\n",
        "            inter_mask[label == sample_label] = 1\n",
        "            inter_mask = torch.from_numpy(inter_mask).to(device)\n",
        "            inter_mask_list.append(inter_mask)\n",
        "            #Reshape The GT\n",
        "            if int_time < 1:\n",
        "                gt_density = F.interpolate(gt_density, size=(inter_mask.shape[0], inter_mask.shape[1]),\n",
        "                                           mode='bilinear').squeeze()\n",
        "\n",
        "            #Updating with Interaction\n",
        "            optimizer_inter = optim.Adam(adapted_regressor.parameters(), lr=INLR)\n",
        "            features.required_grad = True\n",
        "            for step in range(0, INGS):\n",
        "                #Inter Opti\n",
        "                optimizer_inter.zero_grad()\n",
        "                output = adapted_regressor(features).squeeze()\n",
        "                inter_loss = 0\n",
        "                #Scheme 2\n",
        "                for inmask in inter_mask_list:\n",
        "                  inter_loss += interactive_loss(output, gt_density, inmask)\n",
        "                inter_loss /= len(inter_mask_list)\n",
        "                #inter_loss = criterion((output * inter_mask).sum(), (gt_density * inter_mask).sum())\n",
        "                if torch.is_tensor(inter_loss):\n",
        "                    inter_loss.backward()\n",
        "                    optimizer_inter.step()\n",
        "\n",
        "            '''\n",
        "            After Interaction\n",
        "            '''\n",
        "\n",
        "            features.required_grad = False\n",
        "            output = adapted_regressor(features).squeeze()\n",
        "            pred_cnt = output.sum().item()\n",
        "            gt_cnt = dots.shape[0]\n",
        "            cnt = cnt + 1\n",
        "            err = gt_cnt - pred_cnt\n",
        "            inter_result[int_time].append(err)\n",
        "        assert len(inter_mask_list) == 5\n",
        "    return inter_result\n",
        "\n",
        "###############################################Adaptation##############################################\n",
        "ADLR = 1e-7\n",
        "GS = 100\n",
        "weight_mincount = 1e-9\n",
        "weight_perturbation = 1e-4\n",
        "\n",
        "###############################################Interaction#############################################\n",
        "Inter_time = 5\n",
        "INGS = 15\n",
        "INLR = 1e-6\n",
        "Test_Adaptation = True\n",
        "show_detail = False\n",
        "\n",
        "\n",
        "\n",
        "Inter_result = adapted_test()\n",
        "for inter_time in range(Inter_time):\n",
        "    image_errs = Inter_result[inter_time]\n",
        "    image_errs = np.array(image_errs)\n",
        "    mse = np.sqrt(np.mean(np.square(image_errs)))\n",
        "    mae = np.mean(np.abs(image_errs))\n",
        "    print('mae {}, mse {}\\n'.format(mae, mse))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adapted Test on FSC147 train set data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3613: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/content/gdrive/My Drive/Interactive Counting/utils.py:297: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss += F.mse_loss(X,ones)\n",
            "/content/gdrive/My Drive/Interactive Counting/region_sum_less_4.py:64: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  REGION_BOTTOM_BOUND = min(np.rint(total / prediction) * CONUT_LIMIT, 150)\n",
            "/content/gdrive/My Drive/Interactive Counting/region_sum_less_4.py:174: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  REGION_BOTTOM_BOUND = min(np.rint(total / prediction) * 10, 150)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mae 19.694719589007, mse 100.95795170909494\n",
            "\n",
            "mae 18.20501208906414, mse 100.18371545229476\n",
            "\n",
            "mae 16.834745543143327, mse 95.91496295771849\n",
            "\n",
            "mae 15.757186303719752, mse 91.70434725399909\n",
            "\n",
            "mae 14.658328902721404, mse 87.17309467878239\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMTODe4jG7C2"
      },
      "source": [
        "##Sum Region Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2KB8QWmG9vv",
        "outputId": "066e15f1-0890-499f-c1b7-ff51378e1d07"
      },
      "source": [
        "def adapted_test():\n",
        "    inter_result = [[], [], [], [], []]\n",
        "    show_detail = False\n",
        "    print(\"Adapted Test on FSC147 train set data\")\n",
        "    MAPS = ['map3', 'map4']\n",
        "    Scales = [0.9, 1.1]\n",
        "    idx_list = list(range(len(test_dataset)))\n",
        "    SAE = 0\n",
        "    SSE = 0\n",
        "    cnt = 0\n",
        "    starttime = datetime.datetime.now()\n",
        "    criterion = torch.nn.MSELoss().cuda()\n",
        "    \n",
        "    for idx in idx_list:\n",
        "        test_sample = test_dataset[idx]\n",
        "        im_id, image, boxes, dots, bg_mask_img, density = test_sample['im_id'], test_sample['image'], test_sample['boxes'], test_sample['dots'], test_sample['bg_mask_img'], test_sample['gt_density']\n",
        "        sample = {'image': image, 'lines_boxes': boxes, 'gt_density': density}\n",
        "        sample = TransformTrain(sample)\n",
        "        image, boxes, gt_density = sample['image'].to(device), sample['boxes'].to(device), sample['gt_density'].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            features = extract_features(resnet50_conv, image.unsqueeze(0), boxes.unsqueeze(0), MAPS, Scales)\n",
        "        adapted_regressor = copy.deepcopy(regressor)\n",
        "\n",
        "        '''\n",
        "        Do the Test-Adaptation\n",
        "        '''\n",
        "\n",
        "        if Test_Adaptation:\n",
        "          adapted_regressor.train()\n",
        "          optimizer = optim.Adam(adapted_regressor.parameters(), lr=ADLR)\n",
        "          features.required_grad = True\n",
        "          for step in range(0, GS):\n",
        "              optimizer.zero_grad()\n",
        "              output = adapted_regressor(features)\n",
        "              lCount = weight_mincount * MincountLoss(output, boxes)\n",
        "              lPerturbation = weight_perturbation * PerturbationLoss(output, boxes, sigma=8)\n",
        "              loss = lCount + lPerturbation\n",
        "              if torch.is_tensor(loss):\n",
        "                  loss.backward()\n",
        "                  optimizer.step()\n",
        "\n",
        "        '''\n",
        "        Interaction\n",
        "        '''\n",
        "        inter_mask_list = []\n",
        "        for int_time in range(Inter_time):\n",
        "            #Inference\n",
        "            features.required_grad = False\n",
        "            output = adapted_regressor(features)\n",
        "\n",
        "            #VIS\n",
        "            density = output.squeeze().detach().cpu().numpy()\n",
        "            visual = VIS(density)\n",
        "            visual.solve()\n",
        "            label = visual.Llabel\n",
        "\n",
        "            #Sample Region Randomly\n",
        "            sample_label = random_region_sample(label)\n",
        "\n",
        "            #Get Mask\n",
        "            inter_mask = np.zeros((label.shape[0], label.shape[1]), dtype=np.uint8)\n",
        "            inter_mask[label == sample_label] = 1\n",
        "            inter_mask = torch.from_numpy(inter_mask).to(device)\n",
        "            inter_mask_list.append(inter_mask)\n",
        "            #Reshape The GT\n",
        "            if int_time < 1:\n",
        "                gt_density = F.interpolate(gt_density, size=(inter_mask.shape[0], inter_mask.shape[1]),\n",
        "                                           mode='bilinear').squeeze()\n",
        "\n",
        "            #Updating with Interaction\n",
        "            optimizer_inter = optim.Adam(adapted_regressor.parameters(), lr=INLR)\n",
        "            features.required_grad = True\n",
        "            for step in range(0, INGS):\n",
        "                #Inter Opti\n",
        "                optimizer_inter.zero_grad()\n",
        "                output = adapted_regressor(features).squeeze()\n",
        "                inter_loss = 0\n",
        "                #Scheme 2\n",
        "                for inmask in inter_mask_list:\n",
        "                  inter_loss += interactive_loss(output, gt_density, inmask)\n",
        "                #inter_loss /= len(inter_mask_list)\n",
        "                #inter_loss = criterion((output * inter_mask).sum(), (gt_density * inter_mask).sum())\n",
        "                if torch.is_tensor(inter_loss):\n",
        "                    inter_loss.backward()\n",
        "                    optimizer_inter.step()\n",
        "\n",
        "            '''\n",
        "            After Interaction\n",
        "            '''\n",
        "\n",
        "            features.required_grad = False\n",
        "            output = adapted_regressor(features).squeeze()\n",
        "            pred_cnt = output.sum().item()\n",
        "            gt_cnt = dots.shape[0]\n",
        "            cnt = cnt + 1\n",
        "            err = gt_cnt - pred_cnt\n",
        "            inter_result[int_time].append(err)\n",
        "        assert len(inter_mask_list) == 5\n",
        "    return inter_result\n",
        "\n",
        "###############################################Adaptation##############################################\n",
        "ADLR = 1e-7\n",
        "GS = 100\n",
        "weight_mincount = 1e-9\n",
        "weight_perturbation = 1e-4\n",
        "\n",
        "###############################################Interaction#############################################\n",
        "Inter_time = 5\n",
        "INGS = 15\n",
        "INLR = 1e-6\n",
        "Test_Adaptation = True\n",
        "show_detail = False\n",
        "\n",
        "\n",
        "\n",
        "Inter_result = adapted_test()\n",
        "for inter_time in range(Inter_time):\n",
        "    image_errs = Inter_result[inter_time]\n",
        "    image_errs = np.array(image_errs)\n",
        "    mse = np.sqrt(np.mean(np.square(image_errs)))\n",
        "    mae = np.mean(np.abs(image_errs))\n",
        "    print('mae {}, mse {}\\n'.format(mae, mse))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adapted Test on FSC147 train set data\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3613: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/content/gdrive/My Drive/Interactive Counting/utils.py:297: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss += F.mse_loss(X,ones)\n",
            "/content/gdrive/My Drive/Interactive Counting/region_sum_less_4.py:64: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  REGION_BOTTOM_BOUND = min(np.rint(total / prediction) * CONUT_LIMIT, 150)\n",
            "/content/gdrive/My Drive/Interactive Counting/region_sum_less_4.py:174: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  REGION_BOTTOM_BOUND = min(np.rint(total / prediction) * 10, 150)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mae 19.2671100853371, mse 96.20158140836493\n",
            "\n",
            "mae 17.51394738645113, mse 92.07405334825438\n",
            "\n",
            "mae 16.176223489667187, mse 87.33918497794693\n",
            "\n",
            "mae 15.141395441974913, mse 83.50529005451658\n",
            "\n",
            "mae 13.619852527900903, mse 77.96976805540083\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AALoIjXoHYw7"
      },
      "source": [
        "#Error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNRZS4V8HbCN"
      },
      "source": [
        "##Mean Region Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OS_iTRUKF_62",
        "outputId": "d9464860-b67f-420f-99a8-67eb8de89928"
      },
      "source": [
        "def adapted_test():\n",
        "    inter_result = [[], [], [], [], []]\n",
        "    show_detail = False\n",
        "    print(\"Adapted Test on FSC147 train set data\")\n",
        "    MAPS = ['map3', 'map4']\n",
        "    Scales = [0.9, 1.1]\n",
        "    idx_list = list(range(len(test_dataset)))\n",
        "    SAE = 0\n",
        "    SSE = 0\n",
        "    cnt = 0\n",
        "    starttime = datetime.datetime.now()\n",
        "    criterion = torch.nn.MSELoss().cuda()\n",
        "    \n",
        "    for idx in idx_list:\n",
        "        test_sample = test_dataset[idx]\n",
        "        im_id, image, boxes, dots, bg_mask_img, density = test_sample['im_id'], test_sample['image'], test_sample['boxes'], test_sample['dots'], test_sample['bg_mask_img'], test_sample['gt_density']\n",
        "        sample = {'image': image, 'lines_boxes': boxes, 'gt_density': density}\n",
        "        sample = TransformTrain(sample)\n",
        "        image, boxes, gt_density = sample['image'].to(device), sample['boxes'].to(device), sample['gt_density'].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            features = extract_features(resnet50_conv, image.unsqueeze(0), boxes.unsqueeze(0), MAPS, Scales)\n",
        "        adapted_regressor = copy.deepcopy(regressor)\n",
        "\n",
        "        '''\n",
        "        Do the Test-Adaptation\n",
        "        '''\n",
        "\n",
        "        if Test_Adaptation:\n",
        "          adapted_regressor.train()\n",
        "          optimizer = optim.Adam(adapted_regressor.parameters(), lr=ADLR)\n",
        "          features.required_grad = True\n",
        "          for step in range(0, GS):\n",
        "              optimizer.zero_grad()\n",
        "              output = adapted_regressor(features)\n",
        "              lCount = weight_mincount * MincountLoss(output, boxes)\n",
        "              lPerturbation = weight_perturbation * PerturbationLoss(output, boxes, sigma=8)\n",
        "              loss = lCount + lPerturbation\n",
        "              if torch.is_tensor(loss):\n",
        "                  loss.backward()\n",
        "                  optimizer.step()\n",
        "\n",
        "        '''\n",
        "        Interaction\n",
        "        '''\n",
        "        inter_mask_list = []\n",
        "        for int_time in range(Inter_time):\n",
        "            #Inference\n",
        "            features.required_grad = False\n",
        "            output = adapted_regressor(features)\n",
        "\n",
        "            #VIS\n",
        "            density = output.squeeze().detach().cpu().numpy()\n",
        "            visual = VIS(density)\n",
        "            visual.solve()\n",
        "            label = visual.Llabel\n",
        "            \n",
        "            #Reshape The GT\n",
        "            if int_time < 1:\n",
        "                gt_density = F.interpolate(gt_density, size=(label.shape[0], label.shape[1]),\n",
        "                                           mode='bilinear').squeeze()\n",
        "\n",
        "            #Sample Region Randomly\n",
        "            #sample_label = random_region_sample(label)\n",
        "            sample_label = error_region_sample(label, output.squeeze(), gt_density)\n",
        "\n",
        "            #Get Mask\n",
        "            inter_mask = np.zeros((label.shape[0], label.shape[1]), dtype=np.uint8)\n",
        "            inter_mask[label == sample_label] = 1\n",
        "            inter_mask = torch.from_numpy(inter_mask).to(device)\n",
        "            inter_mask_list.append(inter_mask)\n",
        "            \n",
        "\n",
        "            #Updating with Interaction\n",
        "            optimizer_inter = optim.Adam(adapted_regressor.parameters(), lr=INLR)\n",
        "            features.required_grad = True\n",
        "            for step in range(0, INGS):\n",
        "                #Inter Opti\n",
        "                optimizer_inter.zero_grad()\n",
        "                output = adapted_regressor(features).squeeze()\n",
        "                inter_loss = 0\n",
        "                #Scheme 2\n",
        "                for inmask in inter_mask_list:\n",
        "                  inter_loss += interactive_loss(output, gt_density, inmask)\n",
        "                inter_loss /= len(inter_mask_list)\n",
        "                #inter_loss = criterion((output * inter_mask).sum(), (gt_density * inter_mask).sum())\n",
        "                if torch.is_tensor(inter_loss):\n",
        "                    inter_loss.backward()\n",
        "                    optimizer_inter.step()\n",
        "\n",
        "            '''\n",
        "            After Interaction\n",
        "            '''\n",
        "\n",
        "            features.required_grad = False\n",
        "            output = adapted_regressor(features).squeeze()\n",
        "            pred_cnt = output.sum().item()\n",
        "            gt_cnt = dots.shape[0]\n",
        "            cnt = cnt + 1\n",
        "            err = gt_cnt - pred_cnt\n",
        "            inter_result[int_time].append(err)\n",
        "        assert len(inter_mask_list) == 5\n",
        "    return inter_result\n",
        "\n",
        "###############################################Adaptation##############################################\n",
        "ADLR = 1e-7\n",
        "GS = 100\n",
        "weight_mincount = 1e-9\n",
        "weight_perturbation = 1e-4\n",
        "\n",
        "###############################################Interaction#############################################\n",
        "Inter_time = 5\n",
        "INGS = 15\n",
        "INLR = 1e-6\n",
        "Test_Adaptation = True\n",
        "show_detail = False\n",
        "\n",
        "\n",
        "\n",
        "Inter_result = adapted_test()\n",
        "for inter_time in range(Inter_time):\n",
        "    image_errs = Inter_result[inter_time]\n",
        "    image_errs = np.array(image_errs)\n",
        "    mse = np.sqrt(np.mean(np.square(image_errs)))\n",
        "    mae = np.mean(np.abs(image_errs))\n",
        "    print('mae {}, mse {}\\n'.format(mae, mse))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adapted Test on FSC147 train set data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3613: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/content/gdrive/My Drive/Interactive Counting/utils.py:297: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss += F.mse_loss(X,ones)\n",
            "/content/gdrive/My Drive/Interactive Counting/region_sum_less_4.py:64: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  REGION_BOTTOM_BOUND = min(np.rint(total / prediction) * CONUT_LIMIT, 150)\n",
            "/content/gdrive/My Drive/Interactive Counting/region_sum_less_4.py:174: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  REGION_BOTTOM_BOUND = min(np.rint(total / prediction) * 10, 150)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mae 16.740911695336095, mse 95.3409088792643\n",
            "\n",
            "mae 16.134597752875642, mse 91.6471490301763\n",
            "\n",
            "mae 16.55251389832056, mse 87.8269311491735\n",
            "\n",
            "mae 16.823071416886915, mse 90.4411943985754\n",
            "\n",
            "mae 15.4305970127843, mse 91.857189692145\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4lzBS-cHtQH"
      },
      "source": [
        "##Sum Region Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jM3RnM7GHwYi",
        "outputId": "600f9cd4-38fe-40e4-bfc3-90996470d617"
      },
      "source": [
        "def adapted_test():\n",
        "    inter_result = [[], [], [], [], []]\n",
        "    show_detail = False\n",
        "    print(\"Adapted Test on FSC147 train set data\")\n",
        "    MAPS = ['map3', 'map4']\n",
        "    Scales = [0.9, 1.1]\n",
        "    idx_list = list(range(len(test_dataset)))\n",
        "    SAE = 0\n",
        "    SSE = 0\n",
        "    cnt = 0\n",
        "    starttime = datetime.datetime.now()\n",
        "    criterion = torch.nn.MSELoss().cuda()\n",
        "    \n",
        "    for idx in idx_list:\n",
        "        test_sample = test_dataset[idx]\n",
        "        im_id, image, boxes, dots, bg_mask_img, density = test_sample['im_id'], test_sample['image'], test_sample['boxes'], test_sample['dots'], test_sample['bg_mask_img'], test_sample['gt_density']\n",
        "        sample = {'image': image, 'lines_boxes': boxes, 'gt_density': density}\n",
        "        sample = TransformTrain(sample)\n",
        "        image, boxes, gt_density = sample['image'].to(device), sample['boxes'].to(device), sample['gt_density'].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            features = extract_features(resnet50_conv, image.unsqueeze(0), boxes.unsqueeze(0), MAPS, Scales)\n",
        "        adapted_regressor = copy.deepcopy(regressor)\n",
        "\n",
        "        '''\n",
        "        Do the Test-Adaptation\n",
        "        '''\n",
        "\n",
        "        if Test_Adaptation:\n",
        "          adapted_regressor.train()\n",
        "          optimizer = optim.Adam(adapted_regressor.parameters(), lr=ADLR)\n",
        "          features.required_grad = True\n",
        "          for step in range(0, GS):\n",
        "              optimizer.zero_grad()\n",
        "              output = adapted_regressor(features)\n",
        "              lCount = weight_mincount * MincountLoss(output, boxes)\n",
        "              lPerturbation = weight_perturbation * PerturbationLoss(output, boxes, sigma=8)\n",
        "              loss = lCount + lPerturbation\n",
        "              if torch.is_tensor(loss):\n",
        "                  loss.backward()\n",
        "                  optimizer.step()\n",
        "\n",
        "        '''\n",
        "        Interaction\n",
        "        '''\n",
        "        inter_mask_list = []\n",
        "        for int_time in range(Inter_time):\n",
        "            #Inference\n",
        "            features.required_grad = False\n",
        "            output = adapted_regressor(features)\n",
        "\n",
        "            #VIS\n",
        "            density = output.squeeze().detach().cpu().numpy()\n",
        "            visual = VIS(density)\n",
        "            visual.solve()\n",
        "            label = visual.Llabel\n",
        "            \n",
        "            #Reshape The GT\n",
        "            if int_time < 1:\n",
        "                gt_density = F.interpolate(gt_density, size=(label.shape[0], label.shape[1]),\n",
        "                                           mode='bilinear').squeeze()\n",
        "\n",
        "            #Sample Region Randomly\n",
        "            #sample_label = random_region_sample(label)\n",
        "            sample_label = error_region_sample(label, output.squeeze(), gt_density)\n",
        "\n",
        "            #Get Mask\n",
        "            inter_mask = np.zeros((label.shape[0], label.shape[1]), dtype=np.uint8)\n",
        "            inter_mask[label == sample_label] = 1\n",
        "            inter_mask = torch.from_numpy(inter_mask).to(device)\n",
        "            inter_mask_list.append(inter_mask)\n",
        "            \n",
        "\n",
        "            #Updating with Interaction\n",
        "            optimizer_inter = optim.Adam(adapted_regressor.parameters(), lr=INLR)\n",
        "            features.required_grad = True\n",
        "            for step in range(0, INGS):\n",
        "                #Inter Opti\n",
        "                optimizer_inter.zero_grad()\n",
        "                output = adapted_regressor(features).squeeze()\n",
        "                inter_loss = 0\n",
        "                #Scheme 2\n",
        "                for inmask in inter_mask_list:\n",
        "                  inter_loss += interactive_loss(output, gt_density, inmask)\n",
        "                #inter_loss /= len(inter_mask_list)\n",
        "                #inter_loss = criterion((output * inter_mask).sum(), (gt_density * inter_mask).sum())\n",
        "                if torch.is_tensor(inter_loss):\n",
        "                    inter_loss.backward()\n",
        "                    optimizer_inter.step()\n",
        "\n",
        "            '''\n",
        "            After Interaction\n",
        "            '''\n",
        "\n",
        "            features.required_grad = False\n",
        "            output = adapted_regressor(features).squeeze()\n",
        "            pred_cnt = output.sum().item()\n",
        "            gt_cnt = dots.shape[0]\n",
        "            cnt = cnt + 1\n",
        "            err = gt_cnt - pred_cnt\n",
        "            inter_result[int_time].append(err)\n",
        "        assert len(inter_mask_list) == 5\n",
        "    return inter_result\n",
        "\n",
        "###############################################Adaptation##############################################\n",
        "ADLR = 1e-7\n",
        "GS = 100\n",
        "weight_mincount = 1e-9\n",
        "weight_perturbation = 1e-4\n",
        "\n",
        "###############################################Interaction#############################################\n",
        "Inter_time = 5\n",
        "INGS = 15\n",
        "INLR = 1e-6\n",
        "Test_Adaptation = True\n",
        "show_detail = False\n",
        "\n",
        "\n",
        "\n",
        "Inter_result = adapted_test()\n",
        "for inter_time in range(Inter_time):\n",
        "    image_errs = Inter_result[inter_time]\n",
        "    image_errs = np.array(image_errs)\n",
        "    mse = np.sqrt(np.mean(np.square(image_errs)))\n",
        "    mae = np.mean(np.abs(image_errs))\n",
        "    print('mae {}, mse {}\\n'.format(mae, mse))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adapted Test on FSC147 train set data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3613: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/content/gdrive/My Drive/Interactive Counting/utils.py:297: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss += F.mse_loss(X,ones)\n",
            "/content/gdrive/My Drive/Interactive Counting/region_sum_less_4.py:64: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  REGION_BOTTOM_BOUND = min(np.rint(total / prediction) * CONUT_LIMIT, 150)\n",
            "/content/gdrive/My Drive/Interactive Counting/region_sum_less_4.py:174: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  REGION_BOTTOM_BOUND = min(np.rint(total / prediction) * 10, 150)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mae 16.740954189641133, mse 95.34193864958591\n",
            "\n",
            "mae 16.14323665384485, mse 91.63923502448615\n",
            "\n",
            "mae 16.61852484350445, mse 87.90295244123591\n",
            "\n",
            "mae 16.74307229819418, mse 84.27955402643296\n",
            "\n",
            "mae 15.251377227526753, mse 79.61165357820126\n",
            "\n"
          ]
        }
      ]
    }
  ]
}